Assignment 2
========================================================

Data 

The data for this assignment are the Samsung activity data available from the course website: 

https://spark-public.s3.amazonaws.com/dataanalysis/samsungData.rda

These data are slightly processed to make them easier to load into R. You can also find the raw data here: 

http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones 

All of the columns of the data set (except the last two) represents one measurement from the Samsung phone. The variable subject indicates which subject was performing the tasks when the measurements were taken. The variable activity tells what activity they were performing.  

Prompt 

Your task is to build a function that predicts what activity a subject is performing based on the quantitative measurements from the Samsung phone. For this analysis your training set must include the data from subjects 1, 3, 5, and 6.  But you may use more subjects data to train if you wish. Your test set is the data from subjects 27, 28, 29, and 30, but you may use more data to test. Be careful that your training/test sets do not overlap.  

You should perform all of the steps in building a predictive model and describe your analysis in a report as explained below.  


What you should submit

Your data analysis submission will consist of the following components: 
The main text of your document including a numbered list of references. This can be uploaded either as a pdf document or typed into the text box (not both!). The limit for the text and references is 2000 words. Your main text should be written in the form of an essay with an introduction, methods, results, and conclusions section. 
One figure for your data analysis uploaded as a .png, .jpg, or .pdf file, along with a figure caption of up to 500 words. 
Reproducibility 

Due to security concerns with the exchange of R code, you will no longer be asked to submit code to reproduce your analyses. I still believe reproducibility is a key component of data analysis and I encourage you to create reproducible code for your data analysis.  

Submission Deadline 

You must submit your data analysis by December 8, 2013 at 11:59PM UTC-5:00 (Baltimore time). No late days may be applied to the data analysis. Note that this is an extension of the original date posted on the class website.  


Steps in Data Analysis
-----------------------------------

**1. Define the question**     

"Build a function that predicts what activity a subject is performing based on the quantitative measurements from the Samsung phone "

**2. Determine the ideal data set**    
"data from samsung phones and the activity concerned withthe data".

**3. Determine what data you can acess**    
Data can be acessed via     
https://spark-public.s3.amazonaws.com/dataanalysis/samsungData.rda    
  
or    
   
http://archive.ics.uci.edu/ml/datasets/Human+Activity+Recognition+Using+Smartphones   

**4. Obtain the data**

```{r}
#download.file("http://spark-public.s3.amazonaws.com/dataanalysis/samsungData.rda", "../data/samsungData.rda",)
getwd()
setwd("E:/courses/coursera/data analysis 002/assignment 2/code/rawcode")
# 
data = load("../../data/samsungData.rda")
dt = data
samsungData[1:2,]


```
**5.Clean the data**  

Understand the source of the data (census, sample, convenience sample, etc.) : Sample
May need reformating, subsampling - record these steps : 
Subsampling required :

Generate Test and training data set
----------------------------------------------

```{r}

#  now we use fresh approach as illustrated inn the slide

# set 70 -30 percent for train and test
samsungData$trainIndicator = 0
#samsungData$trainIndicator
samsungData$trainIndicator = rbinom(nrow(samsungData),size = 1, prob = 0.95)
table(samsungData$trainIndicator)
table(samsungData$activity[samsungData$trainIndicator ==1])
table(samsungData$activity[samsungData$trainIndicator ==0])
# observation shows almost porportional representation of activites in the train and test data. which is good

#constraint subject 1,3,5,6 must be in training set
samsungData$trainIndicator[samsungData$subject %in% c(1,3,5,6)]
table(samsungData$trainIndicator[samsungData$subject %in% c(1,3,5,6)])
samsungData$trainIndicator[samsungData$subject %in% c(1,3,5,6)] = 1

#constraint subject 27:30 must be in test set
samsungData$trainIndicator[samsungData$subject %in% c(27:30)] = 0

# new summary, see what is the ration  of train to test
table(samsungData$trainIndicator)
 
#(60-40 percent training and test set)
# It is very important to have poportional representation in your training and testing data set. Since te value we are going to estimate is the activity here, we should have porportional representation of the activity i.e  the model will not be good if we say we have in training set 4000 of sitting activity and  of standing activity, een if it is 70 -30 percent in training and testing data set.
# creating train data set
dim(samsungData)

# get subset data without subject and trainIndicator Column as they are redundant columns
tr_dt = subset(samsungData, trainIndicator == 1)
ts_dt = subset(samsungData, trainIndicator == 0)
dim(ts_dt)

subjectColNum = grep("subject",names(tr_dt))
trainIndColNum = grep("trainIndicator",names(tr_dt))
##remove subject column and trainIndicator Column
tr_dt = tr_dt[ ,-(c(subjectColNum,trainIndColNum))]
dim(tr_dt)
ts_dt = ts_dt[ ,-(c(subjectColNum,trainIndColNum))]
dim(ts_dt)


#also delete activity column foroutlier detection accepts the data fraame with numeric value only.
numeric_data_4_outlier_detection = tr_dt[,1:561]
dt_numeric_cols_only = numeric_data_4_outlier_detection

# shifted data with all numeric cols and activity
head(tr_dt)
shifted_tr_dt = tr_dt
names(shifted_tr_dt)
shifted_tr_dt[,1:561] = shifted_tr_dt[,1:561] +1.1
names(shifted_tr_dt)


```

Missing Value
--------------------------------------

6.1.1 Missing values
```{r}

#quantile(), not possible, assuming one quantile anlysis takes 1 min, 560 takes 560 mins is like 10 hrs just to do quantile.
#best option hence is to use summary  and then just look at it surfacially for  missing values, extreme values, wrong units

#check for missing values.
nrow(dt)
table(complete.cases(dt))
# no missing values observed. all  observation have values
```


Outlier DEtection
------------------------------------------------

```{r}

# for detailed description see the "POutlier Dectction variou techniques.rmd file"

## Create function to compute the test statistic.
rval = function(y){
       ares = abs(y - mean(y))/sd(y) 
       df = data.frame(y, ares)
       r = max(df$ares)
       list(r, df)}

esd = function(y){
  ## Define values and vectors.
  n = length(y)
  alpha = 0.05
  lam = c(1:10)
  R = c(1:10)
  
  ## Compute test statistic until r=10 values have been
  ## removed from the sample.
  for (i in 1:10){
  
  if(i==1){
  rt = rval(y)
  R[i] = unlist(rt[1])
  df = data.frame(rt[2])
  newdf = df[df$ares!=max(df$ares),]}
  
  else if(i!=1){
  rt = rval(newdf$y)
  R[i] = unlist(rt[1])
  df = data.frame(rt[2])
  newdf = df[df$ares!=max(df$ares),]}
  
  ## Compute critical value.
  p = 1 - alpha/(2*(n-i+1))
  t = qt(p,(n-i-1))
  lam[i] = t*(n-i) / sqrt((n-i-1+t**2)*(n-i+1))
  }
  # caclulate the no of outliers based on the R and critical value data
  # Answers : How many outliers does the data set contain ?
  for( i in 1:10){
    if(R[i] > lam[i]){
      return(lam[i])
      break
    }  
  }
}  


# pass the input data to the outlier function, numeric_data_4_outlier_detection
# since 561 columns, we print only columns that has outliers.  Print names and no of outliers for further exploratory analysis

printResult = function(){
    no_of_cols_with_outliers = 0;            
    for(i in 1:ncol(numeric_data_4_outlier_detection)){      
      newdf1 = 0;              
      newdf1 =  esd(numeric_data_4_outlier_detection[,i])
      if(is.numeric(newdf1) && newdf1 >= 1 ){
        no_of_cols_with_outliers = no_of_cols_with_outliers +1
        print(paste(no_of_cols_with_outliers,"Column No : ",i,colnames(numeric_data_4_outlier_detection[i]),"=>","Estimated outliers No : ",as.integer(newdf1)))            
      }  
    }
}

hist(numeric_data_4_outlier_detection[,1])
plot(numeric_data_4_outlier_detection[,1])
printResult()
dim(numeric_data_4_outlier_detection)

```


Apply centering and scaling
---------------------

```{r}
library(caret)
# check for the need to center . Another better way would be to compute how many variables need centering i.e has mean not zero.Could use cutoff value i.e Could have considered variables 0.1>m>-0.1 to be acceptable limit. then compute the no of variable with non zero mean or not centered. If no of variables without zero mean is large use centering and if small, could have left out.
test_centering = numeric_data_4_outlier_detection
mean(test_centering[,1])
test_centering[1:19,1]
hist(test_centering[,1])

# centering cause the variables to have zero mean

cen_dt = predict(preProcess(numeric_data_4_outlier_detection, method = c("center")), numeric_data_4_outlier_detection )
mean(cen_dt[,1])
cen_dt[1:19,1]
par(mfrow = c(1,2))
hist(test_centering[,1])
hist(cen_dt[,1])


# apply centering adn scaling on new transformed data boxcox_dt

cen_scl_dt = predict(preProcess(boxcox_dt, method = c("center","scale")), boxcox_dt )

#data inspection for bpox office if has been applied
boxcox_dt[1:5,1] # datbefore box cox
cen_scl_dt[1:5,1] # data after box cox

```
**Centering not done, although it will have increased he numeircla stability of the models. Rejected becuse it causes loss in interpretability, which is our prime concern for this project.**

Data Scaling
------
```{r}
# check for the need to scale
test_centering = numeric_data_4_outlier_detection
sd(test_centering[,1])
#scaling causes sd to be 1.

```
**Scaling also not done. Same reason as for not performing the scaling. although it will have increased he numeircla stability of the models. Rejected becuse it causes loss in interpretability, which is our prime concern for this project.**


DAta Skewness
-------------------------------------------


```{r}
# log means ..
#lambda = 2 i.e y = 5* x^2 means for 1 unit increase in x, means increas of   20 , 45 , 80

# ii. Skewness 
# A general rule of thumb to consider is that skewed data whose ratio of the highest value to the lowest value is greater than 20 have signiﬁcant skewness. applied predictive modeling pg 31

# train data without activity column and without subject. data set containing numeric columns only
numeric_data = tr_dt[,1:561]
library(caret)

#Problem  to estimate skewness: 
#  Problem 1  : lambda value cannot be evaluated for variables containing negative numbers
      #soluion 1: Shift parameter: the shift parameter is a constant c that needs to be added to the data when some of the data are negative.sRc: http://www.medcalc.org/manual/powertransformation.php
      #Box-Cox transformations are designed for non-negative responses, but can be applied to data that have occassional zero or negative values by adding a constant α to the response before applying the power transformation (SRc: http://data.princeton.edu/wws509/notes/c2s10.html)
      # To avoid problems with negative values of the response variable, we add 1/2 to all observations (Src: http://data.princeton.edu/wws509/stata/c2s10.html)    
  non_negative_numeric_data = numeric_data + 1

#  Problem 2  : lambda value cannot be evaluated for variables containing zero as its minimum value (REF BOOK: APPLIED PREDICTIVE MODELING )
    #Solution : because min is zero. Try transforming it to non zero minimum
  non_negative_numeric_data = non_negative_numeric_data + 0.1
    
# CHECK FOR SKEWNESS
# since range such as 1:2 as in skewness = BoxCoxTrans(non_negative_numeric_data[,1:2], fudge =0.3) is not accepted by the boxtrans we have to create a function that loops over and  calculates the skewness for all. function returns only the names of the variables that are skewed.Return left skewed variables and right skewed variables list
dim(non_negative_numeric_data)
# IF LAMBDA CANNOT BE CALCULATED THEN THE FUNCTION BREAKS, improvement : when lambda cannot be computed display the error or adjust the function to not break when lambda not computable
skewList = function(vector2d,fudge = 0.3){  
  ret = c()
  res_left_skewed = c()
  res_right_skewed = c()
  for(i in 1:ncol(vector2d)){
  #for(i in 1:20){
   skewness = BoxCoxTrans(non_negative_numeric_data[,i], fudge = fudge)
  #  adjust for the fudge factor i.e lambda  < 0.7 and lambda > 1.3  only in the list  
   # 2 != 1 and !(2 > 0.7 and  2 < 1.3))   
   if(skewness["lambda"] != 1 && !( ((1-fudge) <= skewness["lambda"])  && (skewness["lambda"]  <= (1+fudge)) )){
  if(skewness["lambda"] < 1){
      res_left_skewed = c(paste(colnames(non_negative_numeric_data[i])," ==> ", skewness["lambda"]),res_left_skewed)
    }else{
      res_right_skewed = c(paste(colnames(non_negative_numeric_data[i])," ==> ", skewness["lambda"]),res_right_skewed)
      }
    }  
  }
  ret$left = res_left_skewed
  ret$right = res_right_skewed  
  return(ret)
}

ret = skewList(non_negative_numeric_data)
#ret
summary(ret$left) # 416 left skewed
summary(ret$right) #  49 right skewed
# no fo observations that were normally distributed  were then
ncol(non_negative_numeric_data) - 416-49  # 96  variables


# apply box cox
boxcox_dt = predict(preProcess(non_negative_numeric_data, method = c("BoxCox")), non_negative_numeric_data )

boxcox_tr_dt = shifted_tr_dt;
boxcox_tr_dt[,1:561] = predict(preProcess(shifted_tr_dt[,1:561], method = c("BoxCox")), shifted_tr_dt[,1:561] )
names(boxcox_tr_dt)
boxcox_tr_dt[1:5,1]

#data inspection for bpox office if has been applied
non_negative_numeric_data[1:5,1] # datbefore box cox
boxcox_dt[1:5,1] # data after box cox

```

**Find variables with zero variance**

```{r}
# find variables with no variance
nearZeroVar(non_negative_numeric_data) # 0 variables with near zero variance


```


Apply PCA
-----------------

```{r}
# apply PCA on new transformed data cen_scl_dt

pca_dt = predict(preProcess(cen_scl_dt, method = c("pca")), cen_scl_dt )

#data inspection for pca if has been applied
cen_scl_dt[1:5,1] # datbefore pca
pca_dt[1:5,1] # data after pca

```
Indv transformation vs all transformation at once
---------------------------------------------

```{r}

# administer and apply a series of transformationnat once

transformation = preProcess(non_negative_numeric_data, method = c("BoxCox","center","scale","pca"),verbose=T, fudge=.3) # define transformation  # observed 93 columns needed that captures 95 percent of the variance :pca
trans_dt = predict(transformation,non_negative_numeric_data )#apply transformation

#data inspection for models appied once or step by step
pca_dt[1:5,1] # step by step results
trans_dt[1:5,1] # all at once
names(trans_dt)

```

## Improvements 1 : Since noly certain columns explain  most of the variance in ur data, you would most probably like to deal with those data sets only. If so then you also would probably most likely likey tocalculate or adjust lambda for those variables only. Instead of all the ones avaialable.

## Imporvements 2 : See if you can group lambda to -2,-1,0.5,0,0.5,1,2 values. They are more interpretable.
## Improvements 3 : TRy PLS rather than pca. PLS is more better as it also considers the variabel to be predicted


Filtering
------------------------

```{r}

nearZeroVar(trans_dt) #ﬁlter near-zero variance predictors, observed 0 v variables that has no variance


```

Find corelated varaibles
------------------

```{r}

tr_dt_1 = cor(tr_dt[,1:560])

cor_mat = cor(tr_dt[,1:560]) # find correlation matrix for all numeric variables, in the tr_dt
library(caret)
high_cor.7 = findCorrelation(cor_mat, cutoff = .7, verbose = T)
high_cor.7 #(vector containing col num that are corelated and are recommended for reduction)

un_cor_dt = tr_dt[,-high_cor.7] # all data with all rows from training set but not the uncorrelated data set.

dim(un_cor_dt)
head(un_cor_dt$activity)

```

Find predictive model
------------------------

**Find predictive model using tree
**

```{r}
# we should remove (,), \,  and - all of them . we canu use this
names(un_cor_dt) = gsub("[(,)-]",".",names(un_cor_dt))
names(un_cor_dt) = gsub("\\.","",names(un_cor_dt))
names(un_cor_dt) = tolower(names(un_cor_dt))
names(un_cor_dt[1:3])

library(tree)
#tree1 = tree(activity ~ tbodyacc.mean...x  , data = un_cor_dt) # err , activity should be a factor for the tree to work
un_cor_dt$activity = as.factor(un_cor_dt$activity)
##un_cor_dt$activity

dim(un_cor_dt)
# model tree
tree1 = tree(activity ~ .-activity  , data = un_cor_dt) # err , activity should be a factor 
summary(tree1) # dev = 0.93, misclassification : 0.16

# model function to test for diff data sets
modelTree = function(tr_dt9){
  names(tr_dt9) = gsub("[(,)-]",".",names(tr_dt9))
  names(tr_dt9) = gsub("\\.","",names(tr_dt9))
  tr_dt9$activity = as.factor(tr_dt9$activity)
  tree2 = tree(activity ~ ., data = tr_dt9) 
  #summary(tree2)   
  return(tree2)
}
 
# 1. tree without correlation on tr_dt
dim(tr_dt)
tree1 = modelTree(tr_dt)# dev = 0.62, misclass: 0.10
summary(tree1)

tree2 = modelTree(un_cor_dt)# dev = 0.93, misclass: 0.16
summary(tree2)
# shifted data, data shifting does not impact the trees. Proven
tree3 = modelTree(shifted_tr_dt) # dev = 0.62, mscl = 0.10
(tree3)
tree1

#Theoritical deduction  centering, and box transformation also does not affect the tree being generated.
tree4 = modelTree(boxcox_tr_dt) # dev = 0.62, mscl = 0.10
tree4 # res is 0.627, err rate is 0.1029
tree1


```
**Find the best cutoff value using cross validation** 
```{r}

  
summary(tree1)
plot(tree1,lwd=2)
text(tree1, label=NULL, cex=.8,  col="blue", pos = 3, adj = c(.5,0.5) ) #this adds the internal labels
text(tree1, splits=FALSE, srt=60, cex=.9, adj=c(1,.8), col = "red") #this adds the leaves

names(tr_dt) = gsub("[(,)-]",".",names(tr_dt))
  tr_dt$activity = as.factor(tr_dt$activity)
  tree1 = tree(activity ~ ., data = tr_dt) 
  
# find the cutoff value, plot errors
?cv.tree
par(mfrow=c(1,3))
plot(cv.tree(tree1, FUN = prune.tree,method = "misclass"))
plot(cv.tree(tree1)) # based on the plots we cut off at 4

```

**Prune the tree**
```{r}
pruneTree1 = prune.tree(tree1,best=4) # this models prunes a tree with only 4 outcomes of the six possible outcomes. Hence we reject this
plot(pruneTree1)
text(pruneTree1)


pruneTree1 = prune.tree(tree1,best=5) # gives 5 outcomes
plot(pruneTree1)
text(pruneTree1)

```

####Expository Figure#

```{r fig.width=7, fig.height=6}

pruneTree1 = prune.tree(tree1,best=6) # gives 6 outcomes
par(mfrow = c(1,1), mar = c(4,4,4,4))
plot(pruneTree1,lwd = 2 )
#title(main = "Decision Tree Model to predict activity", cex = 1, sub = "Figure 1. Decision Tree model to predict activities of 'Individuals' based upon the data obtained from the smartphone. The branches represent the variables representing measurement obtained from the smartphone.")
text(pruneTree1, label=NULL, cex=1.17,  col="blue", pos = 3, adj = c(.5,0.5) ) #this adds the internal labels
text(pruneTree1, splits=FALSE, srt=00, cex=1.3, adj=c(1,.8), col = "red") #this adds the leaves
mtext(text = "Decision Tree model to predict activities of 'Individuals' ", cex = 1.5, side = 3, line=3)

summary(pruneTree1)
#plot(pruneTree1)
#text(pruneTree1)
```


```{r}



#now calculate the new errors for teh new pruned tree
summary(pruneTree1) # devianceis 0.72, misclass : 0.1093 # 90 percent accuracy on the train set
summary(tree1) 
```
**Apply the tree to the new test data**

```{r}
#pred1 = predict(pruneTree1,ts_dt)

# error we have to apply the same transformation with the names as we didi with the traiing set.
names(ts_dt) = gsub("[(,)-]",".",names(ts_dt))
pred1 = predict(pruneTree1,ts_dt,type="class")
head(pred1)
summary(pred1)
pred1

#see error in the train set and the predicted values in the train set
table(tr_dt$activity,predict(pruneTree1,type="class")) 

#see error in the test set and the predicted values in the test set using the tree modeled above
pred = predict(pruneTree1,ts_dt,type="class")
summary(pred)
table(ts_dt$activity,predict(pruneTree1,ts_dt,type="class")) 
accuracy = (339+271+270+255+178+188)/nrow(ts_dt)
accuracy # 87.1 percent accuracy on the test set

dim(tr_dt)
dim(ts_dt)
```

**Calculating accuracy of the models**
```{r}
##install.packages("SDMTools")
##library(SDMTools)
##accuracy(tr_dt$activity,predict(pruneTree1,type="class")) # works only for numerical values

install.packages("StabPerf")
library(StabPerf)

accuracy(tr_dt$activity,predict(pruneTree1,type="class"))
```
Using Linear Models of the data set.
----------------------------

```{r}
# prepare training data 
## linear_tr_dt = shifted_tr_dt
##linear_tr_dt[,1:561] = linear_tr_dt[,1:561] -1.1
##table(linear_tr_dt$activity)
##boxcox_lin_dt = tr_dt

# skewness resolve using Box cox
##boxcox_lin_dt[,1:561] = predict(preProcess(boxcox_lin_dt[,1:561], method = c("BoxCox")) ,boxcox_lin_dt[,1:561])
##table(boxcox_lin_dt$activity)

# remove corelated varaibles
##cor_mat_lin = cor(boxcox_lin_dt[,1:561])
##cor_mat_lin[1:2,1:2]
##dim(boxcox_lin_dt)
##?findCorrelation
##cor_cols_lin = findCorrelation(cor_mat_lin, cutoff= 0.7, verbose = T)
##cor_cols_lin
##dim(boxcox_lin_dt)
##table(boxcox_lin_dt$activity)
##uncor_lin_dt = boxcox_lin_dt[,-cor_cols_lin]
##dim(uncor_lin_dt)
##uncor_lin_dt$activity

# create the model and apply it
##uncor_lin_dt$activity = as.factor(uncor_lin_dt$activity)
##lm = lm(uncor_lin_dt$activity ~ ., data = uncor_lin_dt ) # activity  is of factor varaible, linear model cannot handle factor variable unless transformation to convert it to numeric is done
# However, converting to nuemric is not a good idea, cause numeric data have  certain order properties inbuilt in them e.g 1 is near to 2 vs 1 and 5
# Option 2. create dummy variables to break the variable and then use numeric approach or use logistic regression.

```

**Using Logistic Regression :**

http://www.ats.ucla.edu/stat/r/dae/mlogit.htm

```{r}
## Logistic regression
install.packages("glm2")
library(glm2)

# preparing data, create two data sets, one with all  columsn and with with uncorelateed columsn
#  -------1. FOR DATA SET 1 highly likely to have been not used --------------
trans_logit_dt = tr_dt

# skewness, centering and scaling 
trans_logit_dt[,1:561] = predict(preProcess(trans_logit_dt[,1:561], method = c("center","scale","BoxCox")) ,trans_logit_dt[,1:561])

# uncorrelated variables
cor_logit_mat = cor(trans_logit_dt[,1:561])
cor_logit_mat[1:2,1:2]
#?findCorrelation
cor_logit_cols = findCorrelation(cor_logit_mat, cutoff= 0.7, verbose = T)
uncor_logit_dt = trans_logit_dt[,-cor_logit_cols]
dim(uncor_logit_dt)

# extreme collinearity with applied predictive  modelling book approach. apply it to the reduced set to see if any col else is dropped
reducedCovMat = cov(uncor_logit_dt[ ,1:131])
#install.packages("subselect")
library(subselect)
trimRes = trim.matrix(reducedCovMat)
trimRes$names.discarded # 0 were discarded from the reduced set.

# Applying the transformation to the whole 
fullCovMat = cov(trans_logit_dt[, 1:561])
trimFullSetRes = trim.matrix(fullCovMat)
summary(trimFullSetRes)
summary(trimFullSetRes$trimmedmat) # matrix containing the covariance between varaibles
trimFullSetRes$trimmedmat[1:2,1:2]
trimFullSetRes$names.discarded # only 91 variables are removed
trimFullSetRes$numbers.discarded

uncollinear_dt = trans_logit_dt[,-trimFullSetRes$numbers.discarded]
dim(uncollinear_dt)

#evaluate the model
ctrl = trainControl(method="LGOCV", 
                    summaryFunction = twoClassSummary,
                    classProbs = T,
                    index = list(TrainSet = uncollinear_dt),
                    savePredictions = T
                    )
savePredictions

###ver imp function#######################

accuracy = function(predicted,actual, totalrows){
  correctClassification = 0;
  for(row in 1 : totalrows){
    # rest pred value to 0, for each row
    predActivity = 0; 
    # get the value predicted by model
    max = max(predicted[row,])
    # find out which col the value belongs to
    for(col in 1:6){
      if( max == predicted[row,col]){
          # get the col  number
          predActivity = col
          break
        }
    }
    # if the columnnumber indicates activity as really in the model then increase the correctly classified number
    
    if((predActivity == 1 && actual[row] =="laying")
       || (predActivity == 1 && actual[row] =="laying")
       || (predActivity == 2 && actual[row] =="sitting")
       || (predActivity == 3 && actual[row] =="standing")
       || (predActivity == 4 && actual[row] =="walk")
       || (predActivity == 5 && actual[row] =="walkdown")
       || (predActivity == 6 && actual[row] =="walkup")       
       ){
          correctClassification = correctClassification + 1    
       }      
  }
  accuracy = correctClassification * 100 / totalrows
  print(accuracy)
}
### ver imp accuracy function closes


################## possible not used###################################
# develop  the multinomial logistic regression model  
#install.packages("foreign")
library(foreign)
require(nnet)
#install.packages("ggplot2")
require(ggplot2)
require(reshape2)
library("glm2") 

##############res unconverged model###############
class(uncollinear_dt$activity)
glm = multinom(activity ~ . , data =uncor_logit_dt) 
glm
head(glm)
summary(glm)
# 660 variables res unexpected
dim(uncor_logit_dt)
############# res unconverged model #######

############# START : trying multinom with variables observed relevant in tree #########

colnames(uncor_logit_dt) = gsub("\\.","",colnames(un_cor_logit_dt))
head(names(uncor_logit_dt))
table(uncor_logit_dt$activity)

names(un_cor_dt)
logit_dt1 = un_cor_dt
colnames(logit_dt1) = gsub("\\.","",colnames(logit_dt1))
class(logit_dt1$fbodygyrobandsenergy9162)
class(logit_dt1$activity)

glm_logit_dt1 = multinom(activity ~ fbodygyro.bandsenergy...9.16.2 +tgravityacc.energy...y +tgravityacc.entropy...y + angle.z.gravitymean. + tgravityacc.energy...z + tgravityacc.sma.. + tgravityacc.arcoeff...y.3 + fbodygyro.maxinds.z + fbodygyro.maxinds.x + fbodyaccjerk.maxinds.x
 , data = un_cor_dt, Hess = T, censored = T  )
accuracy(glm_logit_dt1$fitted, un_cor_dt$activity, totalrows = 5629) #  86.67 % accurate



# logistic regression with all variables, check if accuracy is decreased , theoritically accuracy should be more, but lets see
glm2 = multinom(activity ~ ., data = tr_dt) # too many weights cannot compute

####################################### BEst logit model#############
# logistic regression with 132 varaibles after cor removal
glm2 = multinom(activity ~ ., data = un_cor_dt) # too many weights cannot compute
##dim(logit_dt1)
?multinom
accuracy(glm2$fitted, un_cor_dt$activity, totalrows = 5629) #  98.22 % accurate

summary(glm2)



# calculate the confidence interval for the logistic regression as well
confint(glm2)

#head(glm2$fitted-fitted(glm2)) # both mean the same thing


# the accuracy is insanely too much, might be overfitt9ing. check for the test set.
dim(tr_dt)
names(ts_dt)

# same transformations must be applied to the test data
##ts_cor_mat = cor(ts_dt[,1:560]) # find correlation matrix for all numeric variables, in the tr_dt
#high_cor.7 = findCorrelation(cor_mat, cutoff = .7, verbose = T)
#un_cor_dt = tr_dt[,-high_cor.7]
ts_dt_logit = ts_dt
names(ts_dt_logit)=gsub("[(,)-]",".",names(ts_dt_logit))
names(ts_dt_logit) = tolower(names(ts_dt_logit))
ts_dt_logit = as.factor(ts_dt_logit)
colnames(ts_dt_logit)
colnames(ts_dt_logit)=gsub("\\.","",colnames(ts_dt_logit))

# apply the model to the test data
test_res = predict(glm2, newdata =ts_dt_logit,"probs" )
head(test_res[1:2,])
head(ts_dt_logit[1:2,562])
#compute accuracy for the test set
accuracy(test_res, ts_dt_logit$activity, totalrows = 1707) #  94.2 % accurate
head(test_res)
dim(test_res)
dim(ts_dt_logit)

```


```{r}

# test accuracy with transformed data, centered, scaled and boxcox
####################transformation of tr data starts ###############################
head(un_cor_dt[1:2,1:2])
head(samsungData[1:2,1:2]) # confirmed un_cor_dt is data with no transform applied

transformed_un_cor_dt = un_cor_dt
##trans = preProcess(transformed_un_cor_dt[,1:133], method = c("BoxCox"), verbose = T)
##trans[] # inspection shows that no Boxcox was applied as lambda value cannot be estimated, due to negative integres. However unlike expected, no error or messgae was shown. You should be very careful that such instances do not occur. Now correct for the error by shifting the varibles
min(transformed_un_cor_dt[,1:133]) # no add ,´min -1.1, so that we do not havezero and negative values
transformed_un_cor_dt[,1:133] = transformed_un_cor_dt[,1:133] +1.1
min(transformed_un_cor_dt[,1:133])
transformed_un_cor_dt[,1:133] =  predict(preProcess(transformed_un_cor_dt[,1:133], method = c("BoxCox","center","scale"), verbose = T),transformed_un_cor_dt[,1:133] ) 

#head(transformed_un_cor_dt[1:2,1:2])
#head(un_cor_dt[1:2,1:2])

####################transformation of tr data complete ############################### 
# find logistic model and get accuracy on the transformed_un_cor_dt

glm_trans_dt1 = multinom(activity ~., data = transformed_un_cor_dt, Hess = T, censored = T  )

nrow(transformed_un_cor_dt)
accuracy(glm_trans_dt1$fitted, transformed_un_cor_dt$activity, totalrows = nrow(transformed_un_cor_dt)) #  97.9 % accurate
glm_trans_dt1

###################test it on the test set ###
#apply trransformation
transformed_ts_dt = ts_dt_logit
dim(transformed_ts_dt)
min(transformed_ts_dt[,1:561]) 
transformed_ts_dt[,1:561] = transformed_ts_dt[,1:561] +1.1
min(transformed_ts_dt[,1:561])
#names(transformed_ts_dt)
transformed_ts_dt[,1:561] =  predict(preProcess(transformed_ts_dt[,1:561], method = c("BoxCox","center","scale"), verbose = T),transformed_ts_dt[,1:561] ) 

##apply to the test set
glm_trans_dt1
test_res1 = predict(glm_trans_dt1, newdata = transformed_ts_dt , "probs")

#head(test_res1[1:2,])
#head(transformed_ts_dt$activity[1:2])

accuracy(test_res1,transformed_ts_dt$activity, totalrows = nrow(transformed_ts_dt) ) # 92.8 percent, sth must be wrong


```
**For Boxxox transfor only **

```{r}
# test accuracy with transformed data boxcox only
####################transformation of tr data starts ###############################
transformed_un_cor_dt = un_cor_dt
transformed_un_cor_dt[,1:133] = transformed_un_cor_dt[,1:133] +1.1
transformed_un_cor_dt[,1:133] =  predict(preProcess(transformed_un_cor_dt[,1:133], method = c("BoxCox"), verbose = T),transformed_un_cor_dt[,1:133] ) 

####################transformation of tr data complete ############################### 
# find logistic model and get accuracy on the transformed_un_cor_dt

glm_trans_dt1 = multinom(activity ~., data = transformed_un_cor_dt, Hess = T, censored = T  )

accuracy(glm_trans_dt1$fitted, transformed_un_cor_dt$activity, totalrows = nrow(transformed_un_cor_dt)) #  97.9 % accurate
glm_trans_dt1

###################test it on the test set ###
#apply trransformation
transformed_ts_dt = ts_dt_logit
transformed_ts_dt[,1:561] = transformed_ts_dt[,1:561] +1.1
min(transformed_ts_dt[,1:561])
#names(transformed_ts_dt)
transformed_ts_dt[,1:561] =  predict(preProcess(transformed_ts_dt[,1:561], method = c("BoxCox"), verbose = T),transformed_ts_dt[,1:561] ) 

##apply to the test set
glm_trans_dt1
test_res1 = predict(glm_trans_dt1, newdata = transformed_ts_dt , "probs")

#head(test_res1[1:2,])
#head(transformed_ts_dt$activity[1:2])

accuracy(test_res1,transformed_ts_dt$activity, totalrows = nrow(transformed_ts_dt) ) # 88.047 percent, sth must be wrong



#test_res = predict
#head(glm2$fitted - predict.glm(glm1,type="response",newdata = testSA)) 




##??multinom
##glm2$Hessian

#summary(glm2)
#head(logit_dt1$activity) # see what is the first six activity
#head(glm2$fitted)  # see what is the prediction for the first six activity, if all have been categorised as standing or not. prability for each section is given there

logit_dt1$activity[1]


dim(logit_dt1)

#---- cacl accuracy now-----
# find the most appropriate value first.
# get col with max val.
# class(glm2$fitted)
# colnames(max(glm2$fitted[1,]))
# names(glm2$fitted[1,3])
# pred



#############CLOSE : trying multinom with variables observed relevant in tree #########


#### glm1 = glm2(activity ~ ., data = uncollinear_dt, family = "binomial") # use fo binomial famial causes all the outcomes to be 1 or 0  that does reflect what we wnat i.e prediction across 5 intervals so type should be response.
?glm2
glm1 = glm2(activity ~ ., data = uncollinear_dt, family = "binomial")

head(glm1$fitted) #

summary(glm1)

#representing non linear relationship

# building the model, try to use robust logistic model, as we have outliers


```



Logistic Modelling of the data
---------------------------------

Assumptions of the logistic modelling are that 
# centering

# varaibles are uncorelated.
# lesser number of varaible, the more stable the model.


1. For logistic modelling  we apply all the transformation

```{r}



```


Find Confounders (To do later)
---------------------------------------
Two option recognised to deal with confounders.

1. For all possible variable that could be confounders in that they are interdependet and are related tot he outcome as well. Perofm  the control analysis. (But for that also u need model.) 
Qn Which model are u going to use to perform controal analysis? Linear regression, logit regression or svm or some other. 
Hence finding the best model first is absolutely essential. 
Qn .But if u put all the varaibles the it will be preblematic, good model will not be obtained due to redundant varaible. So whatdo we do about it ?
Ans :  First of all remove the highyl corelated variables with some value as  cut off for correlation
Qn. But, what about the confounders. So do we not care about it ?
Ans : No, we have to care for it. But once we fidn out the most relevant varibles. Then we find its possible confounder varaible and then we do the control varaible analysis and then find out the confounders.

Pca should be calculated after confounders  or colinear points have been reduced.

#http://www.r-tutor.com/elementary-statistics/numerical-measures/correlation-coefficient

cor = covariance / sd. cant compute sd for the factor variavble. hence cannot compute the corelation by normal way.
The option then is 
1. polyserail
1. Logistic expression is another way


# polyserial 
install.packages("polycor")
library(polycor)
cor_mat = hetcor(tr_dt)

cor(tr_dt[,1:560])

# To evaluate corelation with outcoe variable activity, we convert it to numeric
cor_dt = samsungData
names(cor_dt)
cor_dt = cor_dt[,-c(562,564)]
dim(cor_dt)
table(cor_dt$activity)
#cor_dt$activity[,cor_dt$activity=="laying"] = 1


samsungData$activity
table(samsungData$activity)
summary(as.integer(samsungData$activity))

cor1 = cor(cor_dt[,1:5])
cor1 # 0.92 for tBodyAcc-std()-Y and tBodyAcc-std()-X
high_cor.7 = findCorrelation(cor1, cutoff = .7, verbose = T)

# test cor between 5 and activity
colnames(cor_dt[5])  # "tBodyAcc-std()-Y"
hetcor_res = hetcor(cor_dt[,5], cor_dt$activity)
hetcor_res[]
hetcor_res$correlations[1,2] # 0.8 hows high correltation between var5 and activity (outcome)


# test cor between 4 and activity
colnames(cor_dt[4]) # "tBodyAcc-std()-X"
hetcor_res = hetcor(cor_dt[,4], cor_dt$activity)
hetcor_res
hetcor_res$correlations[1,2] # 0.79 shows high correltation between var4 and activity (outcome)

# now since 4 and 5 are highly correlated to 4 and 5 and outcome, we are going to see whichone is the confounding varaible by

# Option 1 : using partial correlation


# Option 2 : hardcoding partial correlation
#http://www.statmethods.net/stats/correlations.html
#partial corr between a and b controlling for x, y, z

install.packages("ppcor")
library(ppcor)
spcor.test(cor_dt[,4], cor_dt$activity, cor_dt[,5])

#To determine the stratum boundaries ﬁrst and, in a second step, the stratum sample sizes: 
#strata.cumrootf: cumulative root frequency method by Dalenius and Hodges (1959)
#strata.geo: geometric method by Gunning and Horgan (2004)
#To determine the optimal stratum boundaries and sample sizes in a single step:
#strata.LH: generalized Lavallee-Hidiroglou method with Sethi’s (1963) or Kozak’s (2004) algo-
  

install.packages("stratification")
library(stratification)
x = tr_dt
x[,4] = x[,4] +1.1
summary(x[,4
          +])
lh = strata.LH(x[,4],n = 3)
#dt = var.strata(lh,x)
#dt$args$strata[]
lh
lh$bh # boundary values 0.4 and 1 and over

#stratify  vAR4 based upon BOUNDry VALUES
colnames(x[4])
summary(x["tBodyAcc-std()-X"])
x["tBodyAcc-std()-X"][x[4] <= 0.4]
y = x[x[4] <= 0.4,]
y[,4]

hetcor_res = hetcor(y[,4], y$activity)
hetcor_res # cor is -0.24

# calc cor for second stratified sample
z = x[x[4] > 0.4,]
a = z[z[4] < 1,]
a[,4]

hetcor_res = hetcor(a[,4], a$activity)
hetcor_res # cor is -0.24

# calc cor for third stratified sample
b = z[z[4] >= 1,]
b[,4]

hetcor_resv43 = hetcor(b[,4], b$activity)
hetcor_resv43 # cor is -0.24


#stratify  varaible 5 based upon BOUNDry VALUES
x[,5] = x[,5] +1.1
lh = strata.LH(x[,5],n = 3)
#dt = var.strata(lh,x)
#dt$args$strata[]
lh
lh$bh # boundary values 0.4 and 1 and over
colnames(x[5])

summary(x["tBodyAcc-std()-Y"])
x["tBodyAcc-std()-X"][x[5] <= 0.5]
y = x[x[5] <= 0.5,]
y[,5]

hetcor_res = hetcor(y[,5], y$activity)
hetcor_res # cor is -0.24

# calc cor for second stratified sample
z = x[x[5] > 0.5,]
a = z[z[5] < 1.2,]
a[,5]

hetcor_res = hetcor(a[,5], a$activity)
hetcor_res # cor is -0.24

# calc cor for third stratified sample
b = z[z[5] >= 1.2,]
b[,5]

hetcor_resv43 = hetcor(b[,5], b$activity)
hetcor_resv43 # cor is -0.24


st1 = x[x[4]<=0.4,]
dim(st1)
summary(st1[,4])
st1 =  x[x,]

dt = strata.bh(cor_dt[1:100,4]+1.1, bh = lh$bh, n =3)
dt$Nh


lh[]
lh1 = var.strata(lh)
lh1
print(lh)
plot(lh)

# possible confounder since 4 related to 5 adn 4 re to outcome, and 5 rel to outcome. What to do then.
# Filter confounders or inbetween corelated variables
cor1 = cor(non_negative_numeric_data)
cor1[1:2,1:2]

co1dim(cor1) # 561 varaibles, visual observation of corelation almost impossible, hence use statistical methods
library(caret)
?findCorrelation
high_cor.7 = findCorrelation(cor1, cutoff = .7, verbose = T)
cor1[556,81]

high_cor.7[]

length(high_cor.7) # # 413 columns found to be corelated to each other with cutoff greater than .75
high_cor.7 # columsn numbers suggested to be removed

# 0.7  is considred a good cut off value by 
# http://www.foundasoft.com/index.php?option=com_content&view=article&id=158%3A309correlation-coefficient&catid=37%3Afoundalss-articles&Itemid=1.
# http://www.postgraduateforum.com/thread-16547.

# print list of confounding variables 
paste(colnames(dt[high_cor.7]))

# create data with no confounders 
dt.75 = dt[, -high_cor.75]
dt.9 = dt[, -high_cor.9]
dim(dt.75)
dim(dt.9)

##Creating Dummy Variables. In our case we have no need for dummy variables, since we only have numeric data





**6.4 Perform exploratory analyses (e.g. clustering)**
```{r}
#hCluster = hclust(dist(t(dt[,1:(ncol(dt)-2)])))
#plot(hCluster)
# res : impossible to observe clustering

#hCluster = hclust(dist(t(log10(dt[,1:(ncol(dt)-2)]+1))))
#plot(hCluster)

#??hcluster

```


**Clean Data : Determine if the data are good enough - if not, quit or change data : Good enough**

STEP 6 : Exploratory Analysis
--------------------------------------------

6.1 Look at summaries of the data
6.2 Check for missing data
6.3 Create exploratory plots
6.4 Perform exploratory analyses (e.g. clustering)

**6.1 Look at summaries of the data**

Data are often too big to look at the whole thing
The first step in an analysis is to find problems
When you do these summaries you should be looking for
·   
Missing values
Values outside of expected ranges
Values that seem to be in the wrong units
Mislabled variables/columns
Variables that are the wrong clas



# i. Performing Centering and scaling : all the data are within the range -1 to 1 and are scaled accordingly. Hence no centering and scaling is necessary here.
##summary(samsungData)
