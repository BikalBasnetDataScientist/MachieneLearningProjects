{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TF 2.0 -  Basics.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNiw+NDVzvKaqiEMxYqVZBw",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/beekal/MachieneLearningProjects/blob/master/0%20Basics%20-%20TF/TF_2_0_Basics%20Revision.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rlTyY3IsvEdO",
        "colab_type": "text"
      },
      "source": [
        "# TF 2.0 Topics Covered\n",
        "1. TF.Data : A single point of entry to handle any/ varied data type ranging from pandas, csv, image, text, TfRecordByte e.t.c\n",
        "2. TFX: Tensorflow extended,  which aims to  provided end to end TF ecosystem from its  research/ prototype to  the server deployment. It includes the following  all of  which we will cover in this notebook\n",
        "  -  TF validation : Used to validate the data\n",
        "  -  TF Transform : Used to transform the data to its modeling state\n",
        "  -  TF Modeling / Analysis : Used to create the model and evaluate its performance. Reiterate until satisfactory Metric reached.\n",
        "  - TF Serving: Used to serve the model to production with versioning/ Rollback capabilities.\n",
        "\n",
        "REF: https://www.tensorflow.org/tfx "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8YO0K90gu610",
        "colab_type": "code",
        "outputId": "48c85b46-cbd9-4bfd-c64d-0db310145151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy\n",
        "\n",
        "print(f'TF version : ', tf.__version__)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TF version :  2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fyqkv1Vt0B7x",
        "colab_type": "text"
      },
      "source": [
        "## TF.Data\n",
        "Depending on the data source you wil have to use different TF data load calls\n",
        "  - Data in memory :\n",
        "      - tf.data.Dataset.from_tensors() or\n",
        "      - tf.data.Dataset.from_tensor_slices()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XMSgOjW3zexi",
        "colab_type": "code",
        "outputId": "3c68bd2f-fd4a-4802-cc4e-15bd54e6c3ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "d_mem = tf.data.Dataset.from_tensor_slices([1,2])\n",
        "print(f' Tf.Data from memory : ' ,[e.numpy() for e in d_mem])\n",
        "\n",
        "it = iter(d_mem)\n",
        "print(f' Tf.Data from memory using iterator : ' ,next(it).numpy())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " Tf.Data from memory :  [1, 2]\n",
            " Tf.Data from memory using iterator :  1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4uJkc7P2DQTh",
        "colab_type": "text"
      },
      "source": [
        "### TF.Data: From Mixed datatype\n",
        "  - Use generator to convert each elements into a tf.Data Dataset "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdCgN8jbDK_X",
        "colab_type": "code",
        "outputId": "eca0a9b2-758d-4bf5-c44d-ff3128f44302",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "person_data=  ([{ 'age':18,'name':'Hary' },\n",
        "              { 'age':30,'name':'Sam' }\n",
        "              ])\n",
        "person_data\n",
        "person =  tf.data.Dataset.from_generator( lambda: person_data, {\"age\": tf.int32, \"name\":tf.string}  )\n",
        "print(person)\n",
        "print(list(person.as_numpy_iterator()))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<FlatMapDataset shapes: {age: <unknown>, name: <unknown>}, types: {age: tf.int32, name: tf.string}>\n",
            "[{'age': 18, 'name': b'Hary'}, {'age': 30, 'name': b'Sam'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ybu8cCrS5IN8",
        "colab_type": "text"
      },
      "source": [
        "## TF Transform :\n",
        "We can apply different type of transformations as per our need\n",
        "  - Dataset.map() : Per-Element operations\n",
        "  - Dataset.filter(): Per-element Filter Operation\n",
        "  - Dataset.reduce(): Reduce transfomations to single scalar value\n",
        "  - Dataset.batch(): Per-batch operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BoPnPgkk1XaH",
        "colab_type": "code",
        "outputId": "6a9651ed-eacb-4717-b5c9-c852f3cceab5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141
        }
      },
      "source": [
        "def f(x):\n",
        "  return x+2\n",
        "\n",
        "print('Dataset.map(): All elements Increment by 1')\n",
        "print(list(d_mem.map(lambda x: x+1, num_parallel_calls=2).as_numpy_iterator() ))\n",
        "print(f'Using function ',list(d_mem.map(lambda x: f(x), num_parallel_calls=2).as_numpy_iterator() ))\n",
        "\n",
        "\n",
        "print('\\nDataset.reduce():  With initial intitial_state or starting_val')\n",
        "print(f'=10 ', d_mem.reduce( 10,  lambda x,y: x+y).numpy() )\n",
        "print(f'=0 ', d_mem.reduce( 0,  lambda x,y: x+y).numpy() )"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Dataset.map(): All elements Increment by 1\n",
            "[2, 3]\n",
            "Using function  [3, 4]\n",
            "\n",
            "Dataset.reduce():  With initial intitial_state or starting_val\n",
            "=10  13\n",
            "=0  3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bzy20k7Qli08",
        "colab_type": "text"
      },
      "source": [
        "## TF Transform : Using Python function\n",
        "If you want to use the python function inside teh tensorflow pipeline, you can do so in two ways\n",
        "  - Autograph: Use the function directly in the TF graphs. \n",
        "    - Pro: Easy to use\n",
        "    - Con: Can covert some but not all python codes\n",
        "  - tf.py_function : Define the python function as tf function during its use, indicating that it needs to converted into the tf code\n",
        "    - Pro: Can write  arbitary code and will be supported by TF pipeline without throwing any error\n",
        "    - Con: Generally results in worse performance\n",
        "      - Not parallelised"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFXOuPfM-WoP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9ef27264-2c31-4c4e-f248-072730649c02"
      },
      "source": [
        "def upper1(x: tf.Tensor):\n",
        "  return x+10\n",
        "  \n",
        "person_modf = person.map( lambda x : tf.py_function( func=upper1, inp=[x['age']], Tout=tf.int32) )\n",
        "print(list(person_modf.as_numpy_iterator()) )\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[28, 40]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXK-NL7JykI5",
        "colab_type": "text"
      },
      "source": [
        "## TF.py_function vs TF.distribute.Server\n",
        "The tf.py_function must run in the same address as the python program including the device, hence if you are using the distributed Tensorflow you must  use the tf.distribute.Server instead"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f0aWMhvwnfHf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print(person.map(lambda d: (d['age'] , d['name'])))\n",
        "# print(list(person.map(lambda d: (d['age'] , str(d['name'].numpy()).upper())).as_numpy_iterator() ))\n",
        "# print(person.map( lambda x : upper(x) ).as_numpy_iterator()) \n",
        "# print(person.map( lambda x : upper(x) )) \n",
        "# print(list(person.as_numpy_iterator()))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}