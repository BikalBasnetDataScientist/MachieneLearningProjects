{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 2: Supervised Learning \n",
    "### Building a Student Intervention System"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Classification vs Regression\n",
    "\n",
    "Your goal is to identify students who might need early intervention - which type of supervised machine learning problem is this, classification or regression? Why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Answer:** Idetifying students who might need an early  intervention, is a classification problem. Classification is used to predict the  discrete output variable, while regression is used to estimate the continous output variable. And in the above case, the output variable i.e student needs Intervention is  discrete i.e \"Yes\" or  \"No\", hence we use classification.\n",
    "Ref: https://en.wikipedia.org/wiki/Regression_analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Exploring the Data\n",
    "\n",
    "Let's go ahead and read in the student dataset first.\n",
    "\n",
    "_To execute a code cell, click inside it and press **Shift+Enter**._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student data read successfully!\n"
     ]
    }
   ],
   "source": [
    "# Read student data\n",
    "student_data = pd.read_csv(\"student-data.csv\")\n",
    "print \"Student data read successfully!\"\n",
    "# Note: The last column 'passed' is the target/label, all other are feature columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, can you find out the following facts about the dataset?\n",
    "- Total number of students            :  **Answer** : 395\n",
    "- Number of students who passed          **Answer** : 265\n",
    "- Number of students who failed          **Answer** : 130\n",
    "- Graduation rate of the class (%)       **Answer** : 67.09%\n",
    "- Number of features                     **Answer** : 30\n",
    "\n",
    "_Use the code block below to compute these values. Instructions/steps are marked using **TODO**s._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of students: 395\n",
      "Number of students who passed: 265\n",
      "Number of students who failed: 130\n",
      "Number of features: 30\n",
      "Graduation rate of the class: 67.09%\n"
     ]
    }
   ],
   "source": [
    "# TODO: Compute desired values - replace each '?' with an appropriate expression/function call\n",
    "n_students = student_data.shape[0]\n",
    "n_features = student_data.shape[1] - 1 # 1 i.e 1 column is the target  variable column \n",
    "n_passed = (student_data[student_data.passed=='yes']).shape[0]\n",
    "n_failed = (student_data[student_data.passed=='no']).shape[0]\n",
    "grad_rate = n_passed * 100.0 / n_students\n",
    "print \"Total number of students: {}\".format(n_students)\n",
    "print \"Number of students who passed: {}\".format(n_passed)\n",
    "print \"Number of students who failed: {}\".format(n_failed)\n",
    "print \"Number of features: {}\".format(n_features)\n",
    "print \"Graduation rate of the class: {:.2f}%\".format(grad_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Preparing the Data\n",
    "In this section, we will prepare the data for modeling, training and testing.\n",
    "\n",
    "### Identify feature and target columns\n",
    "It is often the case that the data you obtain contains non-numeric features. This can be a problem, as most machine learning algorithms expect numeric data to perform computations with.\n",
    "\n",
    "Let's first separate our data into feature and target columns, and see if any features are non-numeric.<br/>\n",
    "**Note**: For this dataset, the last column (`'passed'`) is the target or label we are trying to predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature column(s):-\n",
      "['school', 'sex', 'age', 'address', 'famsize', 'Pstatus', 'Medu', 'Fedu', 'Mjob', 'Fjob', 'reason', 'guardian', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n",
      "Target column: passed\n",
      "\n",
      "Feature values:-\n",
      "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  \\\n",
      "0     GP   F   18       U     GT3       A     4     4  at_home   teacher   \n",
      "1     GP   F   17       U     GT3       T     1     1  at_home     other   \n",
      "2     GP   F   15       U     LE3       T     1     1  at_home     other   \n",
      "3     GP   F   15       U     GT3       T     4     2   health  services   \n",
      "4     GP   F   16       U     GT3       T     3     3    other     other   \n",
      "\n",
      "    ...    higher internet  romantic  famrel  freetime goout Dalc Walc health  \\\n",
      "0   ...       yes       no        no       4         3     4    1    1      3   \n",
      "1   ...       yes      yes        no       5         3     3    1    1      3   \n",
      "2   ...       yes      yes        no       4         3     2    2    3      3   \n",
      "3   ...       yes      yes       yes       3         2     2    1    1      5   \n",
      "4   ...       yes       no        no       4         3     2    1    2      5   \n",
      "\n",
      "  absences  \n",
      "0        6  \n",
      "1        4  \n",
      "2       10  \n",
      "3        2  \n",
      "4        4  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "# Extract feature (X) and target (y) columns\n",
    "feature_cols = list(student_data.columns[:-1])  # all columns but last are features\n",
    "target_col = student_data.columns[-1]  # last column is the target/label\n",
    "print \"Feature column(s):-\\n{}\".format(feature_cols)\n",
    "print \"Target column: {}\".format(target_col)\n",
    "\n",
    "X_all = student_data[feature_cols]  # feature values for all students\n",
    "y_all = student_data[target_col]  # corresponding targets/labels\n",
    "print \"\\nFeature values:-\"\n",
    "print X_all.head()  # print the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess feature columns\n",
    "\n",
    "As you can see, there are several non-numeric columns that need to be converted! Many of them are simply `yes`/`no`, e.g. `internet`. These can be reasonably converted into `1`/`0` (binary) values.\n",
    "\n",
    "Other columns, like `Mjob` and `Fjob`, have more than two values, and are known as _categorical variables_. The recommended way to handle such a column is to create as many columns as possible values (e.g. `Fjob_teacher`, `Fjob_other`, `Fjob_services`, etc.), and assign a `1` to one of them and `0` to all others.\n",
    "\n",
    "These generated columns are sometimes called _dummy variables_, and we will use the [`pandas.get_dummies()`](http://pandas.pydata.org/pandas-docs/stable/generated/pandas.get_dummies.html?highlight=get_dummies#pandas.get_dummies) function to perform this transformation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed feature columns (48):-\n",
      "['school_GP', 'school_MS', 'sex_F', 'sex_M', 'age', 'address_R', 'address_U', 'famsize_GT3', 'famsize_LE3', 'Pstatus_A', 'Pstatus_T', 'Medu', 'Fedu', 'Mjob_at_home', 'Mjob_health', 'Mjob_other', 'Mjob_services', 'Mjob_teacher', 'Fjob_at_home', 'Fjob_health', 'Fjob_other', 'Fjob_services', 'Fjob_teacher', 'reason_course', 'reason_home', 'reason_other', 'reason_reputation', 'guardian_father', 'guardian_mother', 'guardian_other', 'traveltime', 'studytime', 'failures', 'schoolsup', 'famsup', 'paid', 'activities', 'nursery', 'higher', 'internet', 'romantic', 'famrel', 'freetime', 'goout', 'Dalc', 'Walc', 'health', 'absences']\n"
     ]
    }
   ],
   "source": [
    "# Preprocess feature columns\n",
    "def preprocess_features(X):\n",
    "    outX = pd.DataFrame(index=X.index)  # output dataframe, initially empty\n",
    "\n",
    "    # Check each column\n",
    "    for col, col_data in X.iteritems():\n",
    "        # If data type is non-numeric, try to replace all yes/no values with 1/0\n",
    "        if col_data.dtype == object:\n",
    "            col_data = col_data.replace(['yes', 'no'], [1, 0])\n",
    "        # Note: This should change the data type for yes/no columns to int\n",
    "\n",
    "        # If still non-numeric, convert to one or more dummy variables\n",
    "        if col_data.dtype == object:\n",
    "            col_data = pd.get_dummies(col_data, prefix=col)  # e.g. 'school' => 'school_GP', 'school_MS'\n",
    "\n",
    "        outX = outX.join(col_data)  # collect column(s) in output dataframe\n",
    "\n",
    "    return outX\n",
    "\n",
    "X_all = preprocess_features(X_all)\n",
    "print \"Processed feature columns ({}):-\\n{}\".format(len(X_all.columns), list(X_all.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   school_GP  school_MS  sex_F  sex_M  age  address_R  address_U  famsize_GT3  \\\n",
      "0          1          0      1      0   18          0          1            1   \n",
      "1          1          0      1      0   17          0          1            1   \n",
      "2          1          0      1      0   15          0          1            0   \n",
      "3          1          0      1      0   15          0          1            1   \n",
      "4          1          0      1      0   16          0          1            1   \n",
      "\n",
      "   famsize_LE3  Pstatus_A    ...     higher  internet  romantic  famrel  \\\n",
      "0            0          1    ...          1         0         0       4   \n",
      "1            0          0    ...          1         1         0       5   \n",
      "2            1          0    ...          1         1         0       4   \n",
      "3            0          0    ...          1         1         1       3   \n",
      "4            0          0    ...          1         0         0       4   \n",
      "\n",
      "   freetime  goout  Dalc  Walc  health  absences  \n",
      "0         3      4     1     1       3         6  \n",
      "1         3      3     1     1       3         4  \n",
      "2         3      2     2     3       3        10  \n",
      "3         2      2     1     1       5         2  \n",
      "4         3      2     1     2       5         4  \n",
      "\n",
      "[5 rows x 48 columns]\n"
     ]
    }
   ],
   "source": [
    "print X_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split data into training and test sets\n",
    "\n",
    "So far, we have converted all _categorical_ features into numeric values. In this next step, we split the data (both features and corresponding labels) into training and test sets.\n",
    "\n",
    "** Key Takeaway : Remove Data bias i.e ordering, no of class sets (Stratified sampling)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full set: 395 samples\n",
      "Training set: 300 samples\n",
      "Test set: 95 samples\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# First, decide how many training vs test samples you want\n",
    "num_all = student_data.shape[0]  # same as len(student_data)\n",
    "num_train = 300  # about 75% of the data\n",
    "num_test = num_all - num_train\n",
    "\n",
    "# TODO: Then, select features (X) and corresponding labels (y) for the training and test sets\n",
    "# Note: Shuffle the data or randomly select samples to avoid any bias due to ordering in the dataset\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_all,y_all, test_size = (num_test *1.0 /num_all), random_state = 40)\n",
    "\n",
    "#X_train = ?\n",
    "#y_train = ?\n",
    "#X_test = ?\n",
    "#y_test = ?\n",
    "print \"Full set: {} samples\".format(X_all.shape[0])\n",
    "print \"Training set: {} samples\".format(X_train.shape[0])\n",
    "print \"Test set: {} samples\".format(X_test.shape[0])\n",
    "# Note: If you need a validation set, extract it from within training data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluating Models\n",
    "Choose 3 supervised learning models that are available in scikit-learn, and appropriate for this problem. For each model:\n",
    "\n",
    "- What are the general applications of this model? What are its strengths and weaknesses?\n",
    "- Given what you know about the data so far, why did you choose this model to apply?\n",
    "- Fit this model to the training data, try to predict labels (for both training and test sets), and measure the F<sub>1</sub> score. Repeat this process with different training set sizes (100, 200, 300), keeping test set constant.\n",
    "\n",
    "Produce a table showing training time, prediction time, F<sub>1</sub> score on training set and F<sub>1</sub> score on test set, for each training set size.\n",
    "\n",
    "Note: You need to produce 3 such tables - one for each model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ANSWER : Analysis of  Available Supervised Learning models to chosse  3 supervised learning models**\n",
    "\n",
    "\n",
    "**1. Decision Tree :** [REf: 1]       \n",
    "    General Application : Operations Research, specially in the decision analysis process i. e To identify a strategy that most likely reaches a desired goal.[15] (Both classification and regression problem can be solved using it)\n",
    "    Strengths           \n",
    "  -  Understandability, Sturdy model( not requires  data normalisation, dummy variables, outlier, missing values resolution and sustains model generation assumption violations )\n",
    "  - Logathermic Scalability with data size,  Categorical and numerical values support\n",
    "  - MultiClass Problem solver\n",
    "  - Scalable \n",
    "    \n",
    "Weaknesses\n",
    "  - Biased tree for unbalanced classes\n",
    "  - Overfitting problem (Solve by : Pruning, no of records to split or max depth)  ,\n",
    "  - Sensitive to Small data variations(e.g variable remodeling / addition /removal)\n",
    "  - No Global optimal model gurantee ( because of Local optimal splits)\n",
    "  - Cannot model certain  solutions i.e XOR or multiplexer.   \n",
    "   \n",
    "    In Our case reason for choosing will probably be : Understandability + Categorical and numerical values support\n",
    "    \n",
    "**2. Random Forest :**            \n",
    "    General Application  : Used in the genetics, neuroscience[16] . Often  for both classification (RandomForestClassifier) and regression (RandomForestRegression)             \n",
    "    Strengths           \n",
    "  -  Increased variance (Better accuracy model )\n",
    "  -  Scalable (due to parallelisation possibility)\n",
    "    \n",
    "Weakness\n",
    "  -   Lost understandability              \n",
    "           \n",
    "\n",
    "**3. Naive Bayes : **            \n",
    "    General Application  : Classification  i.e Text categorisation e.g document classification, spam filtering. Also is used in  automatic medical diagnosis.            \n",
    "    Strengths             \n",
    "  -  Irrelevant attributes (Curse of dimensionality) and noise handler (REf 2)\n",
    "  -  Small Data size (can  estimate parameters even with small data size). [3]\n",
    "  -  Highly scalable - Extremeley fast model generation [3] \n",
    "    \n",
    "Weakness  \n",
    "  -   Probability  Predicted Badly estimated ( Predicted probability should not be taken too seriously)        \n",
    "  -   Outperformed by other approaches as Boosted trees or random forest( A 2006 study) [4]\n",
    "\n",
    "\n",
    "**4. Logistic Regression : **            \n",
    "    General Application  : Regression i.e mostly in medical and social sciences[6] (Trauma and Injury Severity Score, Patient severity assesment, Disease presence Prediction). Engineering (Predict failure of machiene, system, process). Marketing (Predict Customer's preference)   and classification (Binomial, Ordinaal and multinominal), the outcome prediction variable is encoded as 0 or 1             \n",
    "    Strengths             \n",
    "  -  Incremental Data addition to training model  efficiently supported [5]\n",
    "    \n",
    "Weakness  \n",
    "  -   Limited expressive power (cannot model ) [5]        \n",
    "  -   Cannot model S- shaped or other  class separating hyperplanes for different classes\n",
    "  -   Makes non sensical prediction for binary dependent varaibles. in such cases logit transformation i.e binary to continous value transformation is done, based on event occuracny probability.\n",
    "                         \n",
    "\n",
    "**4. K-nn : **            \n",
    "    General Application  : Often used in pattern recognition. Classification  and Regression (sklearn.neighbors.KNeighborsClassifier and  KNeighborsRegressor)      \n",
    "    Strengths             \n",
    "  -  Incremental Data (New training examples )addition to training model  efficiently supported and easy [5]\n",
    "  -  simple and powerful. No complex tuning required[8]\n",
    "  \n",
    "Weakness  \n",
    "  -   Expensive and slow Not scalable i.e to compute nearest neighbours, have to compute  distance to all m training examples[8]\n",
    "  -   Must select proper meaningful distance function for higher accuracy\n",
    "  -   Suffers from Curse of dimensionality : i.e higher no of dimensions less effective [7]\n",
    "  -   Optimal Choice of K. Is highly data dependent.        \n",
    "  -   Performance Suffers from class distribution problem i.e skewed class distribution, examples of a more frequent class tend to dominate the prediction of the new example\n",
    "  \n",
    "**4. SVM : **            \n",
    "    General Application  : Data classification and many industrial scale applications. Classification, Regression and outliers detection [9]             \n",
    "    Strengths         \n",
    "  -  Usually Works very well [11]  \n",
    "  -  Effective in high dimensional space [9]\n",
    "  -  Can model complex separating hyperplanes\n",
    "  -  Memory efficient, as only uses a subset of training  point to generate the hyperplanes.[9]\n",
    "  -  Diff kernel function to model different  separating hyperplanes [9]\n",
    "  -  Effective in cases where number of dimension is greater than the number of training examples.[9]\n",
    "  \n",
    "Weakness  \n",
    "  -   Need to select good kernel function[11]\n",
    "  -   requires a lot of memory and cpu time [11]\n",
    "  -   Numerical stability problems in some cases. [11]\n",
    "  -   Does not  directly provide probability estimates. Expensive 5- fold cross validation used if needed[9]\n",
    "  -   Expensive for multi class problem, as it is directly applicable to two class tasks only. Models multi class to several binary class task. [10]\n",
    "  -   Suffers from Performance , if number of dimensions is muh greater than training samples[9]\n",
    "  \n",
    "  \n",
    "**4. Neural Network : **            \n",
    "    General Application  : Classification, Regression and  a wide variety of complex tasks hard to solve, such as  computer vision, speech recognition, time series prediction, fitness approximation,sequence recognition, novelty detection and sequential decision making. System identification and control (Vehicle control, trajectory prediction, natural resource management), quantum chemistry, pattern recognition(radar system, face identification, object recognition), sequence recognition( gesture, speech, handwriting recognition), medical diagnosis, financial applicationi.e automated trading e.t.c  [12]             \n",
    "    Strengths         \n",
    "  -  Can solve large no of complex challenges \n",
    "  -  Fast application [14]\n",
    "  -  Can handle large no of features / dimensions [14]\n",
    "  \n",
    "Weakness  \n",
    "  -   Slow training time\n",
    "  -   Black box model\n",
    "  -   Scalability. Efficient and large neural networks require considerable processing and storage resources.[11]\n",
    "  -   Requires a lot of tuning  across number of hyperparameters [13]\n",
    "  -   Sensisitve to feature scaling / data normalisation. [13]\n",
    "  \n",
    "\n",
    "REf :\n",
    "1. http://scikit-learn.org/stable/modules/tree.html\n",
    "2. https://www.uni-ulm.de/fileadmin/website_uni_ulm/mawi.inst.110/lehre/ss08/StatMeth/DM_NaiveBayes.pdf\n",
    "3. http://scikit-learn.org/stable/modules/naive_bayes.html#\n",
    "4. http://citeseerx.ist.psu.edu/viewdoc/download;jsessionid=2B17989F2A96894F41613D2363CFED45?doi=10.1.1.122.5901&rep=rep1&type=pdf via https://en.wikipedia.org/wiki/Naive_Bayes_classifier#cite_note-6\n",
    "5. https://www.quora.com/What-are-the-advantages-of-different-classification-algorithms\n",
    "6. https://en.wikipedia.org/wiki/Logistic_regression\n",
    "7. http://scikit-learn.org/stable/modules/neighbors.html#classification\n",
    "8. http://ocw.mit.edu/courses/sloan-school-of-management/15-097-prediction-machine-learning-and-statistics-spring-2012/lecture-notes/MIT15_097S12_lec06.pdf\n",
    "9. http://scikit-learn.org/stable/modules/svm.html\n",
    "10.https://en.wikipedia.org/wiki/Support_vector_machine\n",
    "11. http://u.cs.biu.ac.il/~haimga/Teaching/AI/saritLectures/svm.pdf\n",
    "12. https://en.wikipedia.org/wiki/Artificial_neural_network\n",
    "13. http://scikit-learn.org/dev/modules/neural_networks_supervised.html#\n",
    "14. https://www.coursehero.com/file/p3od0ug/Pros-and-Cons-of-Neural-Network-Cons-Slow-training-time-Hard-to-interpret-Hard/\n",
    "15. https://en.wikipedia.org/wiki/Decision_tree\n",
    "16. http://www.statistik.uni-dortmund.de/useR-2008/slides/Strobl+Zeileis.pdf\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the general applications of this model? What are its strengths and weaknesses?\n",
    "Given what you know about the data so far, why did you choose this model to apply?\n",
    "Fit this model to the training data, try to predict labels (for both training and test sets), and measure the F1 score. Repeat this process with different training set sizes (100, 200, 300), keeping test set constant."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** ANSWERS**          \n",
    "**Given what you know about the data so far, why did you choose this model to apply?**\n",
    "1. Naive Bayes :  Curse of dimensionality(Irrelevant attributes not filtered)  + Probability Prediction not required => makes Naive Bayes a good choice for us .\t  \n",
    "\n",
    "2.  Support Vector machiene :  Not a multi class problem (Expensive for so) + No. of dimension < No of training sample (Bad performance, if so) + No Probability estimate required  + SVm's capacity to model complex separting hyperplanes => makes SVM a feasible choice. \n",
    "\n",
    "3. Random Forest :  Robustness in the face of  noise +  irrelevant attributes +  Good performance + Understandability of the model  less prioirity to  performance - > makes Random forest a good choice\n",
    "\n",
    "**Fit this model to the training data, try to predict labels (for both training and test sets), and measure the F1 score. Repeat this process with different training set sizes (100, 200, 300), keeping test set constant.**           \n",
    "                 \n",
    "Answer : F1 Score for trainig sample Size            \n",
    "             \n",
    "                   \n",
    "|\t\t\t|TRAIN100\\*\t|TEST100\\*\\*    |TRAIN200\\*\\*\\*\t|Test200\\*\\*\\*\\*\t|TRAIN\\*\\*\\*\\*\\* \t\t|TEST\\*\\*\\*\\*\\*\\*\t\t|\n",
    "|-----------------------------------|-----------|---------------|-----------|-----------|-----------|-----------|\n",
    "|1. Logistic Regression Classifier\t|1\t\t\t|0.72\t\t\t|0.85\t\t|0.75       |0.82\t\t|0.81\t\t|\n",
    "|2. Deccision tree classifier\t\t|0.90\t\t|0.77\t\t\t|0.91\t\t|0.76       |0.92\t\t|0.76\t\t|\n",
    "|3. SVM classifier-SVC\t\t\t\t|0.88\t\t|0.83\t\t\t|0.85\t\t|0.81       |0.87\t\t|0.83\t\t|\n",
    "|4. Naive Bayes\t\t\t\t\t\t|0.768\t\t|0.772\t\t\t|0.769\t\t|0.765      |0.77\t\t|0.79\t\t|\n",
    "|5. Random forest\t\t\t\t\t|0.875\t\t|0.786\t\t\t|0.881\t\t|0.797\t\t|0.886\t\t|0.863\t\t|\n",
    "              \n",
    "               \n",
    "\n",
    "\\*                   : F1 Score on the Training data  for model created using  when 100 training examples         \n",
    "\\*\\*                 : F1 Score on the Test data  for model created using  when 100 training examples             \n",
    "\\*\\*\\*               : F1 Score on the training data  for model created using  when 200 training examples           \n",
    "\\*\\*\\*\\*             : F1 Score on the Test data  for model created using  when 200 training examples                \n",
    "\\*\\*\\*\\*\\*           : F1 Score on the training Size  for model created using  when 300 training examples              \n",
    "\\*\\*\\*\\*\\*\\*         : F1 Score on the Test data  for model created using  when 300 training examples\n",
    "\n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Empty DataFrame\n",
      "Columns: [school_GP, school_MS, sex_F, sex_M, age, address_R, address_U, famsize_GT3, famsize_LE3, Pstatus_A, Pstatus_T, Medu, Fedu, Mjob_at_home, Mjob_health, Mjob_other, Mjob_services, Mjob_teacher, Fjob_at_home, Fjob_health, Fjob_other, Fjob_services, Fjob_teacher, reason_course, reason_home, reason_other, reason_reputation, guardian_father, guardian_mother, guardian_other, traveltime, studytime, failures, schoolsup, famsup, paid, activities, nursery, higher, internet, romantic, famrel, freetime, goout, Dalc, Walc, health, absences]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 48 columns]\n",
      "Empty DataFrame\n",
      "Columns: [school, sex, age, address, famsize, Pstatus, Medu, Fedu, Mjob, Fjob, reason, guardian, traveltime, studytime, failures, schoolsup, famsup, paid, activities, nursery, higher, internet, romantic, famrel, freetime, goout, Dalc, Walc, health, absences, passed]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "print(X_train[1:1])\n",
    "print(student_data[1:1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n"
     ]
    }
   ],
   "source": [
    "# Train a model\n",
    "import time\n",
    "\n",
    "def train_classifier(clf, X_train, y_train):\n",
    "    print \"Training {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    print \"Done!\\nTraining time (secs): {:.3f}\".format(end - start)\n",
    "\n",
    "# TODO: Choose a model, import it and instantiate an object\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "from sklearn import linear_model\n",
    "print(X_train.shape[0]*0.05)\n",
    "# min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.0\n",
      "LogisticRegression(C=100000.0, class_weight=None, dual=False,\n",
      "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
      "          multi_class='ovr', n_jobs=1, penalty='l2', random_state=None,\n",
      "          solver='liblinear', tol=0.0001, verbose=0, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# Train a model\n",
    "import time\n",
    "\n",
    "def train_classifier(clf, X_train, y_train , print_info = 1 ):\n",
    "    if print_info == 1:\n",
    "        print \"Training {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    end = time.time()\n",
    "    train_time = '{:.3f}'.format(end-start)\n",
    "    if print_info == 1: print \"Done!\\nTraining time (secs): {}\".format(train_time)\n",
    "    return train_time\n",
    "\n",
    "# TODO: Choose a model, import it and instantiate an object\n",
    "from sklearn.tree import  DecisionTreeClassifier\n",
    "from sklearn import linear_model\n",
    "print(X_train.shape[0]*0.05)\n",
    "clf_logit = linear_model.LogisticRegression(C=1e5)\n",
    "\n",
    "# Fit model to training data\n",
    "clf_logit_train_time = train_classifier(clf_logit, X_train, y_train, 0)  # note: using entire training set here\n",
    "#print('clf_logit_train_time is ',clf_logit_train_time)\n",
    "print clf_logit  # you can inspect the learned model by printing it\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using LogisticRegression...\n",
      "Done!\n",
      "Prediction time (secs): 0.269999980927\n",
      "F1 score for training set / Training time / Prediction time : 0.820276497696 / 0.009 / 0.270\n"
     ]
    }
   ],
   "source": [
    "# Predict on training set and compute F1 score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def predict_labels(clf, features, target, print_info = 1):\n",
    "    if print_info == 1:\n",
    "        print \"Predicting labels using {}...\".format(clf.__class__.__name__)\n",
    "    start = time.time()\n",
    "    y_pred = clf.predict(features)\n",
    "    end = time.time()\n",
    "    pred_time = '{:.3f}'.format(end -start)\n",
    "    if print_info == 1:\n",
    "        print \"Done!\\nPrediction time (secs): {}\".format(end - start)\n",
    "    return f1_score(target.values, y_pred, pos_label='yes'), pred_time \n",
    "\n",
    "\n",
    "clf_logit_train_f1_score, clf_logit_train_pred_time  = predict_labels(clf_logit, X_train, y_train)\n",
    "print \"F1 score for training set / Training time / Prediction time : {} / {} / {}\". \\\n",
    "        format(clf_logit_train_f1_score, clf_logit_train_time,clf_logit_train_pred_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting labels using LogisticRegression...\n",
      "Done!\n",
      "Prediction time (secs): 0.000999927520752\n",
      "Predicting labels using LogisticRegression...\n",
      "Done!\n",
      "Prediction time (secs): 0.0\n",
      "F1 score for test set: (0.81428571428571428, '0.000')\n"
     ]
    }
   ],
   "source": [
    "# Predict on test data\n",
    "clf_logit_test_f1_score, clf_logit_test_pred_time  = predict_labels(clf_logit, X_test, y_test)\n",
    "print \"F1 score for test set: {}\".format(predict_labels(clf_logit, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(300, 48)\n",
      "(100, 48)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.84827586206896555, '0.000', 0.84057971014492761, '0.000')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train and predict using different training set sizes\n",
    "def train_predict(clf, X_train, y_train, X_test, y_test, verbose = 1):\n",
    "    if verbose == 1 :\n",
    "        print \"------------------------------------------\"\n",
    "        print \"Training set size: {}\".format(len(X_train))\n",
    "    train_classifier(clf, X_train, y_train, verbose)\n",
    "    clf_train_f1_score, clf_train_predict_time =  predict_labels(clf, X_train, y_train,verbose)\n",
    "    clf_test_f1_score, clf_test_predict_time = predict_labels(clf, X_test, y_test,verbose)\n",
    "    if verbose == 1:\n",
    "        print \"F1 score for training set: {}\".format(clf_train_f1_score)\n",
    "        print \"F1 score for test set: {}\".format(clf_test_f1_score)\n",
    "    return clf_train_f1_score, clf_train_predict_time,  clf_test_f1_score, clf_test_predict_time\n",
    "\n",
    "print(X_train.shape)\n",
    "print(X_train[0:100].shape)\n",
    "\n",
    "X_train100, X_test100, y_train100, y_test100 = train_test_split(X_train,y_train, test_size = 200.0/300, random_state = 40)\n",
    "X_train200, X_test200, y_train200, y_test200 = train_test_split(X_train,y_train, test_size = 100.0/300, random_state = 40)\n",
    "train_predict(clf_logit, X_train100, y_train100, X_test, y_test,0 )\n",
    "train_predict(clf_logit, X_train200, y_train200, X_test, y_test,0 )\n",
    "\n",
    "# TODO: Run the helper function above for desired subsets of training data\n",
    "# Note: Keep the test set constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   DecisionTreeClassifier F1-Train 0.928  F1-Test 0.767   Train Time 0.002  Pred Time_AllTrain 0.000   Pred Time AllTest 0.000 \n",
      "                      SVC F1-Train 0.879  F1-Test 0.837   Train Time 0.008  Pred Time_AllTrain 0.005   Pred Time AllTest 0.002 \n",
      "               GaussianNB F1-Train 0.778  F1-Test 0.797   Train Time 0.001  Pred Time_AllTrain 0.000   Pred Time AllTest 0.000 \n",
      "   RandomForestClassifier F1-Train 0.876  F1-Test 0.805   Train Time 0.025  Pred Time_AllTrain 0.001   Pred Time AllTest 0.001 \n"
     ]
    }
   ],
   "source": [
    "# TODO: Train and predict using two other models\n",
    "# Model1 :  dEcistion tree Classifier\n",
    "# min sample to split on  be 5 percent\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "models = ['tree','svm', 'naive','randomforest']\n",
    "for model in models:\n",
    "    if model == 'tree':        \n",
    "        clf = DecisionTreeClassifier(random_state=0, min_samples_split = X_train.shape[0]*0.03)       \n",
    "    if model == 'svm':\n",
    "        clf = svm.SVC()\n",
    "    if model == 'naive':\n",
    "        clf = GaussianNB()\n",
    "    if model == 'randomforest':\n",
    "        clf = RandomForestClassifier(min_samples_split=15 , n_estimators=10)  # 0.90 & 0.85       \n",
    "        \n",
    "    clf_train_time = train_classifier(clf, X_train, y_train,0)  # note: using entire training set here\n",
    "    #print clf  # you can inspect the learned model by printing it\n",
    "    clf_train_f1_score, clf_train_pred_time = predict_labels(clf, X_train, y_train, 0)\n",
    "    clf_test_f1_score, clf_test_pred_time = predict_labels(clf, X_test, y_test, 0)\n",
    "    #print \"F1 score for test set: {}\"\n",
    "\n",
    "    X_train100, X_test100, y_train100, y_test100 = train_test_split(X_train,y_train, test_size = 200.0/300, random_state = 40)\n",
    "    X_train200, X_test200, y_train200, y_test200 = train_test_split(X_train,y_train, test_size = 100.0/300, random_state = 40)\n",
    "    clf_train_f1_score100, clf_train_pred_time100, clf_test_f1_score100, clf_test_pred_time100  =  \\\n",
    "                    train_predict(clf, X_train100, y_train100, X_test, y_test,0 )\n",
    "    clf_train_f1_score200, clf_train_pred_time200, clf_test_f1_score200, clf_test_pred_time200 = \\\n",
    "                train_predict(clf, X_train200, y_train200, X_test, y_test, 0 )\n",
    "    #print \"F1 score - train set / F1 - Test Set / Model Train time / Pred Time on Train set / Pred Time on Test set : \\n\";\n",
    "    print  \"{:>25} F1-Train {:.3f}  F1-Test {:.3f}   Train Time {}  Pred Time_AllTrain {}   Pred Time AllTest {} \".\\\n",
    "        format(clf.__class__.__name__, clf_train_f1_score,clf_test_f1_score, clf_train_time, \\\n",
    "                                                         clf_train_pred_time, clf_test_pred_time   )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.009\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=15,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.00699996948242\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.0019998550415\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.00500011444092\n",
      "F1 score for training set: (0.87858719646799122, '0.005')\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.00200009346008\n",
      "F1 score for test set: (0.83660130718954251, '0.002')\n",
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.000999927520752\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.00100016593933\n",
      "F1 score for training set: 0.87012987013\n",
      "F1 score for test set: 0.835443037975\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.003\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.00300002098083\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.0019998550415\n",
      "F1 score for training set: 0.879478827362\n",
      "F1 score for test set: 0.825806451613\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.87947882736156346, '0.003', 0.82580645161290311, '0.002')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Train and predict using two other models\n",
    "# Model1 :  Support VEcotr machiene\n",
    "from sklearn import svm\n",
    "clf_svm = svm.SVC()\n",
    "\n",
    "train_classifier(clf_svm, X_train, y_train)  # note: using entire training set here\n",
    "print clf  # you can inspect the learned model by printing it\n",
    "predict_labels(clf_svm, X_train, y_train)\n",
    "predict_labels(clf_svm, X_test, y_test)\n",
    "print \"F1 score for training set: {}\".format(predict_labels(clf_svm, X_train, y_train))\n",
    "print \"F1 score for test set: {}\".format(predict_labels(clf_svm, X_test, y_test))\n",
    "\n",
    "X_train100, X_test100, y_train100, y_test100 = train_test_split (X_train, y_train, test_size = 200.0/300, random_state = 40)\n",
    "X_train200, X_test200, y_train200, y_test200 = train_test_split (X_train, y_train, test_size = 100.0/300, random_state = 40)\n",
    "train_predict(clf_svm, X_train100, y_train100, X_test, y_test )\n",
    "train_predict(clf_svm, X_train200, y_train200, X_test, y_test )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GaussianNB...\n",
      "Done!\n",
      "Training time (secs): 0.002\n",
      "GaussianNB()\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.00100016593933\n",
      "F1 score for training set: (0.77750611246943768, '0.001')\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.0\n",
      "F1 score for test set: (0.79710144927536231, '0.000')\n",
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training GaussianNB...\n",
      "Done!\n",
      "Training time (secs): 0.000\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.00100016593933\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.0\n",
      "F1 score for training set: 0.547368421053\n",
      "F1 score for test set: 0.451612903226\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training GaussianNB...\n",
      "Done!\n",
      "Training time (secs): 0.001\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.0\n",
      "Predicting labels using GaussianNB...\n",
      "Done!\n",
      "Prediction time (secs): 0.0\n",
      "F1 score for training set: 0.797101449275\n",
      "F1 score for test set: 0.785185185185\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.79710144927536219, '0.000', 0.78518518518518499, '0.000')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Train and predict using two other models\n",
    "#from sknn.mlp  import Classifier, Layer\n",
    "#clf = Classifier(layers = [Layer(\"Rectifier\", units = 100), Layer(\"Linear\")], learning_rate = 0.02, n_iter=10)\n",
    "#y_valid = nn.predict(X_valid)\n",
    "#score = nn.score(X_test, y_test)\n",
    "#print('score is', score)\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "clf = GaussianNB()\n",
    "#clf = MLPCLassifier()\n",
    "\n",
    "train_classifier(clf, X_train, y_train)  # note: using entire training set here\n",
    "print clf  # you can inspect the learned model by printing it\n",
    "print \"F1 score for training set: {}\".format(predict_labels(clf, X_train, y_train))\n",
    "print \"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test))\n",
    "\n",
    "X_train100, X_test100, y_train100, y_test100 = train_test_split(X_train,y_train, test_size = 200.0/300, random_state = 40)\n",
    "X_train200, X_test200, y_train200, y_test200 = train_test_split(X_train,y_train, test_size = 100.0/300, random_state = 40)\n",
    "train_predict(clf, X_train100, y_train100, X_test, y_test )\n",
    "train_predict(clf, X_train200, y_train200, X_test, y_test )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.019\n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_samples_leaf=1, min_samples_split=15,\n",
      "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
      "            oob_score=False, random_state=None, verbose=0,\n",
      "            warm_start=False)\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.00200009346008\n",
      "F1 score for training set: (0.86681715575620766, '0.002')\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000999927520752\n",
      "F1 score for test set: (0.84137931034482749, '0.001')\n",
      "------------------------------------------\n",
      "Training set size: 100\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.017\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.00100016593933\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000999927520752\n",
      "F1 score for training set: 0.87012987013\n",
      "F1 score for test set: 0.802631578947\n",
      "------------------------------------------\n",
      "Training set size: 200\n",
      "Training RandomForestClassifier...\n",
      "Done!\n",
      "Training time (secs): 0.017\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.00100016593933\n",
      "Predicting labels using RandomForestClassifier...\n",
      "Done!\n",
      "Prediction time (secs): 0.000999927520752\n",
      "F1 score for training set: 0.882943143813\n",
      "F1 score for test set: 0.831168831169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.88294314381270911, '0.001', 0.83116883116883122, '0.001')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: Train and predict using two other models\n",
    "# Model1 :  Support VEcotr machiene\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier(min_samples_split=15 , n_estimators=10)  # 0.90 & 0.85\n",
    "\n",
    "train_classifier(clf, X_train, y_train)  # note: using entire training set here\n",
    "print clf  # you can inspect the learned model by printing it\n",
    "print \"F1 score for training set: {}\".format(predict_labels(clf, X_train, y_train))\n",
    "print \"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test))\n",
    "\n",
    "X_train100, X_test100, y_train100, y_test100 = train_test_split(X_train,y_train, test_size = 200.0/300, random_state = 40)\n",
    "X_train200, X_test200, y_train200, y_test200 = train_test_split(X_train,y_train, test_size = 100.0/300, random_state = 40)\n",
    "train_predict(clf, X_train100, y_train100, X_test, y_test )\n",
    "train_predict(clf, X_train200, y_train200, X_test, y_test )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Choosing the Best Model\n",
    "\n",
    "**5.1 Question : Based on the experiments you performed earlier, in 2-3 paragraphs explain to the board of supervisors what single model you choose as the best model. Which model has the best test F1 score and time efficiency? Which model is generally the most appropriate based on the available data, limited resources, cost, and performance? Please directly compare and contrast the numerical values recored to make your case.**           \n",
    "                     \n",
    "**Answer :**  Support Vector machiene has been selected as the best model, based on the F1 score and the training time.               \n",
    "We observe that the F1 score when tested against the test set for   the Decision tree classifier, SVM, Gaussian Naive Bayes and the RandomForestClassifier were 0.76, 0.83, 0.79 and 0.82 respectively. Amongst them the F1-score of 0.83  and 0.82 of SVM and\n",
    "RandomForestClassifier respectively, were higher  to others (0.76 and 0.79) and hence, our choice was narrowed down to those two models.                     \n",
    "Despite the short model training time(0.009 sec and 0.003) for the  Decision Trees and Naive Bayes respectively, their comparatively lower F1-scores meant, those models were discarded from our consideration. The models would have been likely choice, in case when we had very very large dataset thus making the model building using complex algorithms as SVM and Random Forest a expensive  task in terms of time.                  \n",
    "However because we had a very small dataset  higher F1- score was of higher priority to the   training time taken. Amongst the two models, Random Forest and the SVM narrowed down, the lower training time taken by the SVM i.e 0.029 sec vs 0.086 of the Random Forest, along with the SVM's capability to model comples separating hyper planes in the data,  led us to choose the SVM as our first choice of model.                       \n",
    "Please refer to the table below, illustrating the comparative F1 scores and the Training time required by each model, for further clarification.               \n",
    "\n",
    "|                       |F1-Train       |F1-Test       |Train Time       |Pred Time_AllTrain        |Pred Time All Test      |\n",
    "|-----------------------|-------------- |--------------|-----------------|--------------------------|------------------------|\n",
    "|DecisionTreeClassifier |F1-Train 0.928 |F1-Test 0.767 |Train Time 0.009 | Pred Time_AllTrain 0.001 |Pred Time AllTest 0.000 |\n",
    "|                   SVM |F1-Train 0.879 |F1-Test 0.837 |Train Time 0.029 | Pred Time_AllTrain 0.019 |Pred Time AllTest 0.006 |\n",
    "|            GaussianNB |F1-Train 0.778 |F1-Test 0.797 |Train Time 0.003 | Pred Time_AllTrain 0.002 |Pred Time AllTest 0.001 |\n",
    "|RandomForestClassifier |F1-Train 0.877 |F1-Test 0.821 |Train Time 0.086 | Pred Time_AllTrain 0.005 |Pred Time AllTest 0.003 |\n",
    "\n",
    "                           \n",
    "                                \n",
    "\n",
    "**5.2 Question: In 1-2 paragraphs explain to the board of supervisors in layman's terms how the final model chosen is supposed to work (for example if you chose a Decision Tree or Support Vector Machine, how does it make a prediction).**          \n",
    "                 \n",
    "** Answer :**  \n",
    "Support Vector machiene, is  a supervised learning model, in which given  a set of training examples  belonging to different categories, the examples are represented in a space  such that there is a clear and maximum gap between each categories. [5]\n",
    "The process of building the Support VEctor machiene model can be best explained with the following example.                       \n",
    "Let's say we have a simple board with two different colors of balls (diff colors corollory to categories and all the balls corollory to training examples).Now in SVM, training a model implies building a model, such that there is a clear and maximum gap between each categories i.e  Lets say the  two color balls red and blue, for a simple scenario are placed such that,  red is on the left side and blue is on the right , then in that case, a simple line in the middle of the board  can easily separate the two color balls.  This simple line, that separates the two classes (categories) is what is produced with the SVM during the model creation process.                         \n",
    "To complicate a bit further the above example case, lets say, after some time, the color balls slowly started to diffuse on to each others side and that hence there is no more any straight line that can separate them.In such case, the simple line does not exist and hence we have to find some other way/ technique, so that we can get a separating line that can separate the two classes. Lets say for example , if we project the same balls into any other space i.e by throwing the balls up in the air, and if lets say the  red balls are ligther than blue, then the red balls gets into much higher space than the blue balls and we can easily draw a straight  plane  at some height, that separates the  heavier ball with the lighter ball.   This act of throwing balls in the air is often done during the model training process for complex cases, when no simple line exists to separate the two classes (i.e categories) using complex tehniques i.e diff. kernels. Complex techniques are used by the SVM  to model such complex separating planes. And thus finally, the Support Vector machiene model,  with the separating plane that separates the two classes ( categories) is obtained, in the model training process.                        \n",
    "As for the prediction process,  once the maximum gap separating plane that separates the  categopries(corollory to classes), is found during the training process, the  test examples are then, also projected into the  respective space, as was done for the training examples. Now once the test examples are projected into the complex space (corollory to throwing the ball in the air), then the separating plane,  that separated the categories  in the training set is   projected and   the test examples are classified to the corresponding respective categorties (i.e classes), based on the test examples position on the respective side of the  separating plane i.e In the above balls case, all the  test balls, that  are heavier  than the separating plane, are categorised as blue and vice versa. And thus the prediction is done  for the test examples, using the separating plane obtained from the trained model, by the SVM.           \n",
    "\n",
    "\n",
    "Ref \n",
    "1. https://en.wikipedia.org/wiki/Support_vector_machine\n",
    "\n",
    "** 5.2 Fine-tune the model. Use Gridsearch with at least one important parameter tuned and with at least 3 settings. Use the entire training set for this. **            \n",
    "               \n",
    "** Answer codes below **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 132 candidates, totalling 396 fits\n",
      "[CV] kernel=linear, C=1, class_weight=balanced .......................\n",
      "[CV]  kernel=linear, C=1, class_weight=balanced, score=0.627451 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   1 tasks       | elapsed:    0.0s\n",
      "[CV] kernel=linear, C=1, class_weight=balanced .......................\n",
      "[CV]  kernel=linear, C=1, class_weight=balanced, score=0.666667 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   2 tasks       | elapsed:    0.0s\n",
      "[CV] kernel=linear, C=1, class_weight=balanced .......................\n",
      "[CV]  kernel=linear, C=1, class_weight=balanced, score=0.724138 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   3 tasks       | elapsed:    0.0s\n",
      "[CV] kernel=linear, C=1, class_weight=None ...........................\n",
      "[CV] .. kernel=linear, C=1, class_weight=None, score=0.775194 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   4 tasks       | elapsed:    0.0s\n",
      "[CV] kernel=linear, C=1, class_weight=None ...........................\n",
      "[CV] .. kernel=linear, C=1, class_weight=None, score=0.724409 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   5 tasks       | elapsed:    0.1s\n",
      "[CV] kernel=linear, C=1, class_weight=None ...........................\n",
      "[CV] .. kernel=linear, C=1, class_weight=None, score=0.763359 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done   6 tasks       | elapsed:    0.1s\n",
      "[CV] kernel=linear, C=10, class_weight=balanced ......................\n",
      "[CV]  kernel=linear, C=10, class_weight=balanced, score=0.672897 -   0.1s\n",
      "[Parallel(n_jobs=1)]: Done   7 tasks       | elapsed:    0.3s\n",
      "[CV] kernel=linear, C=10, class_weight=balanced ......................\n",
      "[CV]  kernel=linear, C=10, class_weight=balanced, score=0.642202 -   0.3s\n",
      "[Parallel(n_jobs=1)]: Done   8 tasks       | elapsed:    0.7s\n",
      "[CV] kernel=linear, C=10, class_weight=balanced ......................\n",
      "[CV]  kernel=linear, C=10, class_weight=balanced, score=0.725664 -   0.4s\n",
      "[Parallel(n_jobs=1)]: Done   9 tasks       | elapsed:    1.2s\n",
      "[CV] kernel=linear, C=10, class_weight=None ..........................\n",
      "[CV] . kernel=linear, C=10, class_weight=None, score=0.775194 -   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  10 tasks       | elapsed:    1.5s\n",
      "[CV] kernel=linear, C=10, class_weight=None ..........................\n",
      "[CV] . kernel=linear, C=10, class_weight=None, score=0.724409 -   0.3s\n",
      "[Parallel(n_jobs=1)]: Done  11 tasks       | elapsed:    2.0s\n",
      "[CV] kernel=linear, C=10, class_weight=None ..........................\n",
      "[CV] . kernel=linear, C=10, class_weight=None, score=0.787879 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  12 tasks       | elapsed:    2.1s\n",
      "[CV] kernel=linear, C=100, class_weight=balanced .....................\n",
      "[CV]  kernel=linear, C=100, class_weight=balanced, score=0.703704 -   1.8s\n",
      "[Parallel(n_jobs=1)]: Done  13 tasks       | elapsed:    4.0s\n",
      "[CV] kernel=linear, C=100, class_weight=balanced .....................\n",
      "[CV]  kernel=linear, C=100, class_weight=balanced, score=0.629630 -   7.6s\n",
      "[Parallel(n_jobs=1)]: Done  14 tasks       | elapsed:   11.6s\n",
      "[CV] kernel=linear, C=100, class_weight=balanced .....................\n",
      "[CV]  kernel=linear, C=100, class_weight=balanced, score=0.725664 -   4.3s\n",
      "[Parallel(n_jobs=1)]: Done  15 tasks       | elapsed:   16.1s\n",
      "[CV] kernel=linear, C=100, class_weight=None .........................\n",
      "[CV]  kernel=linear, C=100, class_weight=None, score=0.775194 -   2.7s\n",
      "[Parallel(n_jobs=1)]: Done  16 tasks       | elapsed:   18.9s\n",
      "[CV] kernel=linear, C=100, class_weight=None .........................\n",
      "[CV]  kernel=linear, C=100, class_weight=None, score=0.724409 -   3.5s\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks       | elapsed:   22.5s\n",
      "[CV] kernel=linear, C=100, class_weight=None .........................\n",
      "[CV]  kernel=linear, C=100, class_weight=None, score=0.800000 -   2.3s\n",
      "[Parallel(n_jobs=1)]: Done  18 tasks       | elapsed:   24.9s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=2, class_weight=balanced ...\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=2, class_weight=balanced, score=0.648148 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  19 tasks       | elapsed:   24.9s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=2, class_weight=balanced ...\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=2, class_weight=balanced, score=0.700000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  20 tasks       | elapsed:   24.9s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=2, class_weight=balanced ...\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=2, class_weight=balanced, score=0.776860 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  21 tasks       | elapsed:   24.9s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=2, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=2, class_weight=balanced, score=0.774648 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  22 tasks       | elapsed:   24.9s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=2, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=2, class_weight=balanced, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  23 tasks       | elapsed:   24.9s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=2, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=2, class_weight=balanced, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  24 tasks       | elapsed:   25.0s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=2, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=2, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  25 tasks       | elapsed:   25.0s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=2, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=2, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  26 tasks       | elapsed:   25.0s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=2, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=2, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  27 tasks       | elapsed:   25.0s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=3, class_weight=balanced ...\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=3, class_weight=balanced, score=0.576577 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  28 tasks       | elapsed:   25.1s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=3, class_weight=balanced ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\python27\\lib\\site-packages\\sklearn\\metrics\\classification.py:1074: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  kernel=poly, C=1, gamma=auto, degree=3, class_weight=balanced, score=0.743802 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  29 tasks       | elapsed:   25.1s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=3, class_weight=balanced ...\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=3, class_weight=balanced, score=0.725806 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  30 tasks       | elapsed:   25.1s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=3, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=3, class_weight=balanced, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  31 tasks       | elapsed:   25.1s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=3, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=3, class_weight=balanced, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  32 tasks       | elapsed:   25.1s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=3, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=3, class_weight=balanced, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  33 tasks       | elapsed:   25.2s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=3, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=3, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  34 tasks       | elapsed:   25.2s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=3, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=3, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  35 tasks       | elapsed:   25.2s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=3, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=3, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  36 tasks       | elapsed:   25.2s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=4, class_weight=balanced ...\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=4, class_weight=balanced, score=0.643478 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  37 tasks       | elapsed:   25.2s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=4, class_weight=balanced ...\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=4, class_weight=balanced, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  38 tasks       | elapsed:   25.2s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=4, class_weight=balanced ...\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=4, class_weight=balanced, score=0.709677 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  39 tasks       | elapsed:   25.3s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=4, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=4, class_weight=balanced, score=0.794521 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  40 tasks       | elapsed:   25.3s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=4, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=4, class_weight=balanced, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  41 tasks       | elapsed:   25.3s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=4, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=4, class_weight=balanced, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  42 tasks       | elapsed:   25.3s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=4, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=4, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  43 tasks       | elapsed:   25.3s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=4, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=4, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  44 tasks       | elapsed:   25.3s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=4, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=4, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  45 tasks       | elapsed:   25.3s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=5, class_weight=balanced ...\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=5, class_weight=balanced, score=0.689655 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  46 tasks       | elapsed:   25.4s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=5, class_weight=balanced ...\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=5, class_weight=balanced, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  47 tasks       | elapsed:   25.4s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=5, class_weight=balanced ...\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=5, class_weight=balanced, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  48 tasks       | elapsed:   25.4s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=5, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=5, class_weight=balanced, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  49 tasks       | elapsed:   25.4s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=5, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=5, class_weight=balanced, score=0.808219 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  50 tasks       | elapsed:   25.4s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=5, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=5, class_weight=balanced, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  51 tasks       | elapsed:   25.4s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=5, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=5, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  52 tasks       | elapsed:   25.4s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=5, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=5, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  53 tasks       | elapsed:   25.5s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=5, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=5, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  54 tasks       | elapsed:   25.5s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=6, class_weight=balanced ...\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=6, class_weight=balanced, score=0.689655 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  55 tasks       | elapsed:   25.5s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=6, class_weight=balanced ...\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=6, class_weight=balanced, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  56 tasks       | elapsed:   25.5s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=6, class_weight=balanced ...\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=6, class_weight=balanced, score=0.741935 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  57 tasks       | elapsed:   25.5s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=6, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=6, class_weight=balanced, score=0.805369 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  58 tasks       | elapsed:   25.5s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=6, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=6, class_weight=balanced, score=0.808219 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  59 tasks       | elapsed:   25.5s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=6, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=6, class_weight=balanced, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  60 tasks       | elapsed:   25.6s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=6, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=6, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  61 tasks       | elapsed:   25.6s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=6, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=6, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  62 tasks       | elapsed:   25.6s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=6, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=6, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  63 tasks       | elapsed:   25.6s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=2, class_weight=None .......\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=2, class_weight=None, score=0.846154 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  64 tasks       | elapsed:   25.6s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=2, class_weight=None .......\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=2, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  65 tasks       | elapsed:   25.6s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=2, class_weight=None .......\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=2, class_weight=None, score=0.812030 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  66 tasks       | elapsed:   25.6s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=2, class_weight=None ......\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=2, class_weight=None, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  67 tasks       | elapsed:   25.6s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=2, class_weight=None ......\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=2, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  68 tasks       | elapsed:   25.6s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=2, class_weight=None ......\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=2, class_weight=None, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  69 tasks       | elapsed:   25.6s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=2, class_weight=None .....\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=2, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  70 tasks       | elapsed:   25.6s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=2, class_weight=None .....\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=2, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  71 tasks       | elapsed:   25.6s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=2, class_weight=None .....\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=2, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  72 tasks       | elapsed:   25.7s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=3, class_weight=None .......\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=3, class_weight=None, score=0.584071 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  73 tasks       | elapsed:   25.7s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=3, class_weight=None .......\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=3, class_weight=None, score=0.737705 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  74 tasks       | elapsed:   25.7s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=3, class_weight=None .......\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=3, class_weight=None, score=0.744186 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  75 tasks       | elapsed:   25.7s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=3, class_weight=None ......\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=3, class_weight=None, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  76 tasks       | elapsed:   25.8s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=3, class_weight=None ......\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=3, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  77 tasks       | elapsed:   25.8s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=3, class_weight=None ......\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=3, class_weight=None, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  78 tasks       | elapsed:   25.8s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=3, class_weight=None .....\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=3, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  79 tasks       | elapsed:   25.8s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=3, class_weight=None .....\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=3, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  80 tasks       | elapsed:   25.8s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=3, class_weight=None .....\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=3, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  81 tasks       | elapsed:   25.8s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=4, class_weight=None .......\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=4, class_weight=None, score=0.643478 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  82 tasks       | elapsed:   25.8s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=4, class_weight=None .......\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=4, class_weight=None, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  83 tasks       | elapsed:   25.8s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=4, class_weight=None .......\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=4, class_weight=None, score=0.709677 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  84 tasks       | elapsed:   25.9s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=4, class_weight=None ......\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=4, class_weight=None, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  85 tasks       | elapsed:   25.9s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=4, class_weight=None ......\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=4, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  86 tasks       | elapsed:   25.9s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=4, class_weight=None ......\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=4, class_weight=None, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  87 tasks       | elapsed:   25.9s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=4, class_weight=None .....\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=4, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  88 tasks       | elapsed:   25.9s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=4, class_weight=None .....\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=4, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  89 tasks       | elapsed:   25.9s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=4, class_weight=None .....\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=4, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  90 tasks       | elapsed:   25.9s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=5, class_weight=None .......\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=5, class_weight=None, score=0.689655 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  91 tasks       | elapsed:   25.9s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=5, class_weight=None .......\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=5, class_weight=None, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  92 tasks       | elapsed:   26.0s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=5, class_weight=None .......\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=5, class_weight=None, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  93 tasks       | elapsed:   26.0s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=5, class_weight=None ......\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=5, class_weight=None, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  94 tasks       | elapsed:   26.0s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=5, class_weight=None ......\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=5, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  95 tasks       | elapsed:   26.0s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=5, class_weight=None ......\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=5, class_weight=None, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  96 tasks       | elapsed:   26.0s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=5, class_weight=None .....\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=5, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  97 tasks       | elapsed:   26.0s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=5, class_weight=None .....\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=5, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  98 tasks       | elapsed:   26.0s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=5, class_weight=None .....\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=5, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done  99 tasks       | elapsed:   26.0s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=6, class_weight=None .......\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=6, class_weight=None, score=0.689655 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 100 tasks       | elapsed:   26.0s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=6, class_weight=None .......\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=6, class_weight=None, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 101 tasks       | elapsed:   26.1s\n",
      "[CV] kernel=poly, C=1, gamma=auto, degree=6, class_weight=None .......\n",
      "[CV]  kernel=poly, C=1, gamma=auto, degree=6, class_weight=None, score=0.741935 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 102 tasks       | elapsed:   26.1s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=6, class_weight=None ......\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=6, class_weight=None, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 103 tasks       | elapsed:   26.1s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=6, class_weight=None ......\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=6, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 104 tasks       | elapsed:   26.1s\n",
      "[CV] kernel=poly, C=1, gamma=0.001, degree=6, class_weight=None ......\n",
      "[CV]  kernel=poly, C=1, gamma=0.001, degree=6, class_weight=None, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 105 tasks       | elapsed:   26.1s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=6, class_weight=None .....\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=6, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 106 tasks       | elapsed:   26.1s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=6, class_weight=None .....\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=6, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 107 tasks       | elapsed:   26.1s\n",
      "[CV] kernel=poly, C=1, gamma=0.0001, degree=6, class_weight=None .....\n",
      "[CV]  kernel=poly, C=1, gamma=0.0001, degree=6, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 108 tasks       | elapsed:   26.1s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=2, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=2, class_weight=balanced, score=0.642857 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 109 tasks       | elapsed:   26.2s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=2, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=2, class_weight=balanced, score=0.739496 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 110 tasks       | elapsed:   26.2s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=2, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=2, class_weight=balanced, score=0.728814 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 111 tasks       | elapsed:   26.3s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=2, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=2, class_weight=balanced, score=0.768000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 112 tasks       | elapsed:   26.3s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=2, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=2, class_weight=balanced, score=0.759690 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 113 tasks       | elapsed:   26.3s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=2, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=2, class_weight=balanced, score=0.830769 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 114 tasks       | elapsed:   26.3s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=2, class_weight=balanced \n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=2, class_weight=balanced, score=0.780142 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 115 tasks       | elapsed:   26.3s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=2, class_weight=balanced \n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=2, class_weight=balanced, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 116 tasks       | elapsed:   26.3s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=2, class_weight=balanced \n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=2, class_weight=balanced, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 117 tasks       | elapsed:   26.3s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=3, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=3, class_weight=balanced, score=0.626087 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 118 tasks       | elapsed:   26.3s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=3, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=3, class_weight=balanced, score=0.743802 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 119 tasks       | elapsed:   26.4s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=3, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=3, class_weight=balanced, score=0.693548 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 120 tasks       | elapsed:   26.4s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=3, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=3, class_weight=balanced, score=0.765625 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 121 tasks       | elapsed:   26.4s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=3, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=3, class_weight=balanced, score=0.759690 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 122 tasks       | elapsed:   26.4s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=3, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=3, class_weight=balanced, score=0.809160 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 123 tasks       | elapsed:   26.4s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=3, class_weight=balanced \n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=3, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 124 tasks       | elapsed:   26.5s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=3, class_weight=balanced \n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=3, class_weight=balanced, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 125 tasks       | elapsed:   26.5s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=3, class_weight=balanced \n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=3, class_weight=balanced, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 126 tasks       | elapsed:   26.5s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=4, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=4, class_weight=balanced, score=0.643478 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 127 tasks       | elapsed:   26.5s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=4, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=4, class_weight=balanced, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 128 tasks       | elapsed:   26.5s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=4, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=4, class_weight=balanced, score=0.709677 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 129 tasks       | elapsed:   26.6s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=4, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=4, class_weight=balanced, score=0.782609 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 130 tasks       | elapsed:   26.6s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=4, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=4, class_weight=balanced, score=0.778626 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 131 tasks       | elapsed:   26.6s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=4, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=4, class_weight=balanced, score=0.808824 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 132 tasks       | elapsed:   26.6s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=4, class_weight=balanced \n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=4, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 133 tasks       | elapsed:   26.6s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=4, class_weight=balanced \n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=4, class_weight=balanced, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 134 tasks       | elapsed:   26.6s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=4, class_weight=balanced \n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=4, class_weight=balanced, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 135 tasks       | elapsed:   26.6s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=5, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=5, class_weight=balanced, score=0.689655 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 136 tasks       | elapsed:   26.6s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=5, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=5, class_weight=balanced, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 137 tasks       | elapsed:   26.7s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=5, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=5, class_weight=balanced, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 138 tasks       | elapsed:   26.7s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=5, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=5, class_weight=balanced, score=0.783217 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 139 tasks       | elapsed:   26.7s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=5, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=5, class_weight=balanced, score=0.822695 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 140 tasks       | elapsed:   26.7s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=5, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=5, class_weight=balanced, score=0.802817 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 141 tasks       | elapsed:   26.7s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=5, class_weight=balanced \n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=5, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 142 tasks       | elapsed:   26.7s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=5, class_weight=balanced \n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=5, class_weight=balanced, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 143 tasks       | elapsed:   26.7s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=5, class_weight=balanced \n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=5, class_weight=balanced, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 144 tasks       | elapsed:   26.7s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=6, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=6, class_weight=balanced, score=0.689655 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 145 tasks       | elapsed:   26.8s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=6, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=6, class_weight=balanced, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 146 tasks       | elapsed:   26.8s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=6, class_weight=balanced ..\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=6, class_weight=balanced, score=0.741935 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 147 tasks       | elapsed:   26.8s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=6, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=6, class_weight=balanced, score=0.777778 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 148 tasks       | elapsed:   26.8s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=6, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=6, class_weight=balanced, score=0.794326 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 149 tasks       | elapsed:   26.8s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=6, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=6, class_weight=balanced, score=0.791667 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 150 tasks       | elapsed:   26.8s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=6, class_weight=balanced \n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=6, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 151 tasks       | elapsed:   26.8s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=6, class_weight=balanced \n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=6, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 152 tasks       | elapsed:   26.8s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=6, class_weight=balanced \n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=6, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 153 tasks       | elapsed:   26.9s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=2, class_weight=None ......\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=2, class_weight=None, score=0.660870 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 154 tasks       | elapsed:   26.9s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=2, class_weight=None ......\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=2, class_weight=None, score=0.741935 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 155 tasks       | elapsed:   26.9s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=2, class_weight=None ......\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=2, class_weight=None, score=0.812500 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 156 tasks       | elapsed:   27.0s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=2, class_weight=None .....\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=2, class_weight=None, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 157 tasks       | elapsed:   27.0s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=2, class_weight=None .....\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=2, class_weight=None, score=0.816327 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 158 tasks       | elapsed:   27.0s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=2, class_weight=None .....\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=2, class_weight=None, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 159 tasks       | elapsed:   27.0s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=2, class_weight=None ....\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=2, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 160 tasks       | elapsed:   27.0s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=2, class_weight=None ....\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=2, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 161 tasks       | elapsed:   27.0s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=2, class_weight=None ....\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=2, class_weight=None, score=0.805369 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 162 tasks       | elapsed:   27.0s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=3, class_weight=None ......\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=3, class_weight=None, score=0.631579 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 163 tasks       | elapsed:   27.1s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=3, class_weight=None ......\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=3, class_weight=None, score=0.743802 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 164 tasks       | elapsed:   27.1s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=3, class_weight=None ......\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=3, class_weight=None, score=0.693548 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 165 tasks       | elapsed:   27.1s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=3, class_weight=None .....\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=3, class_weight=None, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 166 tasks       | elapsed:   27.1s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=3, class_weight=None .....\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=3, class_weight=None, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 167 tasks       | elapsed:   27.1s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=3, class_weight=None .....\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=3, class_weight=None, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 168 tasks       | elapsed:   27.2s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=3, class_weight=None ....\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=3, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 169 tasks       | elapsed:   27.2s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=3, class_weight=None ....\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=3, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 170 tasks       | elapsed:   27.2s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=3, class_weight=None ....\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=3, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 171 tasks       | elapsed:   27.2s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=4, class_weight=None ......\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=4, class_weight=None, score=0.643478 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 172 tasks       | elapsed:   27.2s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=4, class_weight=None ......\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=4, class_weight=None, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 173 tasks       | elapsed:   27.2s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=4, class_weight=None ......\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=4, class_weight=None, score=0.709677 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 174 tasks       | elapsed:   27.3s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=4, class_weight=None .....\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=4, class_weight=None, score=0.791946 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 175 tasks       | elapsed:   27.3s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=4, class_weight=None .....\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=4, class_weight=None, score=0.805369 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 176 tasks       | elapsed:   27.3s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=4, class_weight=None .....\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=4, class_weight=None, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 177 tasks       | elapsed:   27.3s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=4, class_weight=None ....\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=4, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 178 tasks       | elapsed:   27.3s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=4, class_weight=None ....\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=4, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 179 tasks       | elapsed:   27.3s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=4, class_weight=None ....\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=4, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 180 tasks       | elapsed:   27.3s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=5, class_weight=None ......\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=5, class_weight=None, score=0.689655 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 181 tasks       | elapsed:   27.3s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=5, class_weight=None ......\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=5, class_weight=None, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 182 tasks       | elapsed:   27.4s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=5, class_weight=None ......\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=5, class_weight=None, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 183 tasks       | elapsed:   27.4s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=5, class_weight=None .....\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=5, class_weight=None, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 184 tasks       | elapsed:   27.4s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=5, class_weight=None .....\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=5, class_weight=None, score=0.805369 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 185 tasks       | elapsed:   27.4s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=5, class_weight=None .....\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=5, class_weight=None, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 186 tasks       | elapsed:   27.4s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=5, class_weight=None ....\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=5, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 187 tasks       | elapsed:   27.4s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=5, class_weight=None ....\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=5, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 188 tasks       | elapsed:   27.4s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=5, class_weight=None ....\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=5, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 189 tasks       | elapsed:   27.4s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=6, class_weight=None ......\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=6, class_weight=None, score=0.689655 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 190 tasks       | elapsed:   27.5s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=6, class_weight=None ......\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=6, class_weight=None, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 191 tasks       | elapsed:   27.5s\n",
      "[CV] kernel=poly, C=10, gamma=auto, degree=6, class_weight=None ......\n",
      "[CV]  kernel=poly, C=10, gamma=auto, degree=6, class_weight=None, score=0.741935 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 192 tasks       | elapsed:   27.5s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=6, class_weight=None .....\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=6, class_weight=None, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 193 tasks       | elapsed:   27.5s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=6, class_weight=None .....\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=6, class_weight=None, score=0.805369 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 194 tasks       | elapsed:   27.5s\n",
      "[CV] kernel=poly, C=10, gamma=0.001, degree=6, class_weight=None .....\n",
      "[CV]  kernel=poly, C=10, gamma=0.001, degree=6, class_weight=None, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 195 tasks       | elapsed:   27.5s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=6, class_weight=None ....\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=6, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 196 tasks       | elapsed:   27.5s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=6, class_weight=None ....\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=6, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 197 tasks       | elapsed:   27.5s\n",
      "[CV] kernel=poly, C=10, gamma=0.0001, degree=6, class_weight=None ....\n",
      "[CV]  kernel=poly, C=10, gamma=0.0001, degree=6, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 198 tasks       | elapsed:   27.6s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=2, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=2, class_weight=balanced, score=0.612613 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 199 tasks       | elapsed:   27.6s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=2, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=2, class_weight=balanced, score=0.705882 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 200 tasks       | elapsed:   27.7s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=2, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=2, class_weight=balanced, score=0.720000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 201 tasks       | elapsed:   27.9s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=2, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=2, class_weight=balanced, score=0.732143 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 202 tasks       | elapsed:   27.9s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=2, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=2, class_weight=balanced, score=0.705882 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 203 tasks       | elapsed:   27.9s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=2, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=2, class_weight=balanced, score=0.780488 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 204 tasks       | elapsed:   27.9s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=2, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=2, class_weight=balanced, score=0.774648 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 205 tasks       | elapsed:   27.9s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=2, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=2, class_weight=balanced, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 206 tasks       | elapsed:   27.9s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=2, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=2, class_weight=balanced, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 207 tasks       | elapsed:   27.9s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=3, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=3, class_weight=balanced, score=0.631579 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 208 tasks       | elapsed:   28.0s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=3, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=3, class_weight=balanced, score=0.743802 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 209 tasks       | elapsed:   28.0s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=3, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=3, class_weight=balanced, score=0.693548 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 210 tasks       | elapsed:   28.1s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=3, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=3, class_weight=balanced, score=0.779661 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 211 tasks       | elapsed:   28.1s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=3, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=3, class_weight=balanced, score=0.733333 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 212 tasks       | elapsed:   28.1s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=3, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=3, class_weight=balanced, score=0.784000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 213 tasks       | elapsed:   28.1s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=3, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=3, class_weight=balanced, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 214 tasks       | elapsed:   28.1s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=3, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=3, class_weight=balanced, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 215 tasks       | elapsed:   28.1s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=3, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=3, class_weight=balanced, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 216 tasks       | elapsed:   28.1s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=4, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=4, class_weight=balanced, score=0.643478 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 217 tasks       | elapsed:   28.1s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=4, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=4, class_weight=balanced, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 218 tasks       | elapsed:   28.2s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=4, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=4, class_weight=balanced, score=0.709677 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 219 tasks       | elapsed:   28.2s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=4, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=4, class_weight=balanced, score=0.776860 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 220 tasks       | elapsed:   28.2s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=4, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=4, class_weight=balanced, score=0.755906 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 221 tasks       | elapsed:   28.2s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=4, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=4, class_weight=balanced, score=0.812500 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 222 tasks       | elapsed:   28.2s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=4, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=4, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 223 tasks       | elapsed:   28.2s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=4, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=4, class_weight=balanced, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 224 tasks       | elapsed:   28.3s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=4, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=4, class_weight=balanced, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 225 tasks       | elapsed:   28.3s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=5, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=5, class_weight=balanced, score=0.689655 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 226 tasks       | elapsed:   28.3s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=5, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=5, class_weight=balanced, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 227 tasks       | elapsed:   28.3s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=5, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=5, class_weight=balanced, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 228 tasks       | elapsed:   28.3s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=5, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=5, class_weight=balanced, score=0.793651 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 229 tasks       | elapsed:   28.4s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=5, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=5, class_weight=balanced, score=0.757576 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 230 tasks       | elapsed:   28.4s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=5, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=5, class_weight=balanced, score=0.812030 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 231 tasks       | elapsed:   28.4s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=5, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=5, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 232 tasks       | elapsed:   28.4s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=5, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=5, class_weight=balanced, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 233 tasks       | elapsed:   28.4s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=5, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=5, class_weight=balanced, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 234 tasks       | elapsed:   28.4s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=6, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=6, class_weight=balanced, score=0.689655 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 235 tasks       | elapsed:   28.4s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=6, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=6, class_weight=balanced, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 236 tasks       | elapsed:   28.4s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=6, class_weight=balanced .\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=6, class_weight=balanced, score=0.741935 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 237 tasks       | elapsed:   28.5s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=6, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=6, class_weight=balanced, score=0.781250 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 238 tasks       | elapsed:   28.5s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=6, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=6, class_weight=balanced, score=0.770370 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 239 tasks       | elapsed:   28.5s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=6, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=6, class_weight=balanced, score=0.820896 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 240 tasks       | elapsed:   28.5s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=6, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=6, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 241 tasks       | elapsed:   28.5s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=6, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=6, class_weight=balanced, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 242 tasks       | elapsed:   28.5s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=6, class_weight=balanced \n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=6, class_weight=balanced, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 243 tasks       | elapsed:   28.5s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=2, class_weight=None .....\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=2, class_weight=None, score=0.614035 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 244 tasks       | elapsed:   28.6s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=2, class_weight=None .....\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=2, class_weight=None, score=0.705882 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 245 tasks       | elapsed:   28.7s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=2, class_weight=None .....\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=2, class_weight=None, score=0.720000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 246 tasks       | elapsed:   28.9s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=2, class_weight=None ....\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=2, class_weight=None, score=0.829630 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 247 tasks       | elapsed:   28.9s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=2, class_weight=None ....\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=2, class_weight=None, score=0.828571 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 248 tasks       | elapsed:   28.9s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=2, class_weight=None ....\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=2, class_weight=None, score=0.823529 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 249 tasks       | elapsed:   28.9s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=2, class_weight=None ...\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=2, class_weight=None, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 250 tasks       | elapsed:   28.9s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=2, class_weight=None ...\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=2, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 251 tasks       | elapsed:   28.9s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=2, class_weight=None ...\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=2, class_weight=None, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 252 tasks       | elapsed:   28.9s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=3, class_weight=None .....\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=3, class_weight=None, score=0.631579 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 253 tasks       | elapsed:   29.0s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=3, class_weight=None .....\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=3, class_weight=None, score=0.743802 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 254 tasks       | elapsed:   29.0s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=3, class_weight=None .....\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=3, class_weight=None, score=0.693548 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 255 tasks       | elapsed:   29.0s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=3, class_weight=None ....\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=3, class_weight=None, score=0.834532 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 256 tasks       | elapsed:   29.0s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=3, class_weight=None ....\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=3, class_weight=None, score=0.814286 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 257 tasks       | elapsed:   29.1s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=3, class_weight=None ....\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=3, class_weight=None, score=0.820144 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 258 tasks       | elapsed:   29.1s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=3, class_weight=None ...\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=3, class_weight=None, score=0.805369 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 259 tasks       | elapsed:   29.1s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=3, class_weight=None ...\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=3, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 260 tasks       | elapsed:   29.1s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=3, class_weight=None ...\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=3, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 261 tasks       | elapsed:   29.1s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=4, class_weight=None .....\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=4, class_weight=None, score=0.643478 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 262 tasks       | elapsed:   29.1s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=4, class_weight=None .....\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=4, class_weight=None, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 263 tasks       | elapsed:   29.2s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=4, class_weight=None .....\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=4, class_weight=None, score=0.709677 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 264 tasks       | elapsed:   29.2s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=4, class_weight=None ....\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=4, class_weight=None, score=0.822695 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 265 tasks       | elapsed:   29.2s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=4, class_weight=None ....\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=4, class_weight=None, score=0.822695 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 266 tasks       | elapsed:   29.2s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=4, class_weight=None ....\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=4, class_weight=None, score=0.811189 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 267 tasks       | elapsed:   29.2s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=4, class_weight=None ...\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=4, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 268 tasks       | elapsed:   29.2s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=4, class_weight=None ...\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=4, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 269 tasks       | elapsed:   29.2s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=4, class_weight=None ...\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=4, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 270 tasks       | elapsed:   29.2s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=5, class_weight=None .....\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=5, class_weight=None, score=0.689655 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 271 tasks       | elapsed:   29.3s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=5, class_weight=None .....\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=5, class_weight=None, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 272 tasks       | elapsed:   29.3s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=5, class_weight=None .....\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=5, class_weight=None, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 273 tasks       | elapsed:   29.3s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=5, class_weight=None ....\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=5, class_weight=None, score=0.813793 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 274 tasks       | elapsed:   29.3s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=5, class_weight=None ....\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=5, class_weight=None, score=0.805556 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 275 tasks       | elapsed:   29.3s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=5, class_weight=None ....\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=5, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 276 tasks       | elapsed:   29.3s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=5, class_weight=None ...\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=5, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 277 tasks       | elapsed:   29.3s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=5, class_weight=None ...\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=5, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 278 tasks       | elapsed:   29.3s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=5, class_weight=None ...\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=5, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 279 tasks       | elapsed:   29.4s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=6, class_weight=None .....\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=6, class_weight=None, score=0.689655 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 280 tasks       | elapsed:   29.4s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=6, class_weight=None .....\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=6, class_weight=None, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 281 tasks       | elapsed:   29.4s\n",
      "[CV] kernel=poly, C=100, gamma=auto, degree=6, class_weight=None .....\n",
      "[CV]  kernel=poly, C=100, gamma=auto, degree=6, class_weight=None, score=0.741935 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 282 tasks       | elapsed:   29.4s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=6, class_weight=None ....\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=6, class_weight=None, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 283 tasks       | elapsed:   29.4s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=6, class_weight=None ....\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=6, class_weight=None, score=0.794521 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 284 tasks       | elapsed:   29.4s\n",
      "[CV] kernel=poly, C=100, gamma=0.001, degree=6, class_weight=None ....\n",
      "[CV]  kernel=poly, C=100, gamma=0.001, degree=6, class_weight=None, score=0.789116 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 285 tasks       | elapsed:   29.5s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=6, class_weight=None ...\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=6, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 286 tasks       | elapsed:   29.5s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=6, class_weight=None ...\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=6, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 287 tasks       | elapsed:   29.5s\n",
      "[CV] kernel=poly, C=100, gamma=0.0001, degree=6, class_weight=None ...\n",
      "[CV]  kernel=poly, C=100, gamma=0.0001, degree=6, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 288 tasks       | elapsed:   29.5s\n",
      "[CV] kernel=sigmoid, C=1, gamma=auto, class_weight=balanced ..........\n",
      "[CV]  kernel=sigmoid, C=1, gamma=auto, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 289 tasks       | elapsed:   29.5s\n",
      "[CV] kernel=sigmoid, C=1, gamma=auto, class_weight=balanced ..........\n",
      "[CV]  kernel=sigmoid, C=1, gamma=auto, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 290 tasks       | elapsed:   29.5s\n",
      "[CV] kernel=sigmoid, C=1, gamma=auto, class_weight=balanced ..........\n",
      "[CV]  kernel=sigmoid, C=1, gamma=auto, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 291 tasks       | elapsed:   29.5s\n",
      "[CV] kernel=sigmoid, C=1, gamma=0.001, class_weight=balanced .........\n",
      "[CV]  kernel=sigmoid, C=1, gamma=0.001, class_weight=balanced, score=0.714286 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 292 tasks       | elapsed:   29.5s\n",
      "[CV] kernel=sigmoid, C=1, gamma=0.001, class_weight=balanced .........\n",
      "[CV]  kernel=sigmoid, C=1, gamma=0.001, class_weight=balanced, score=0.266667 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 293 tasks       | elapsed:   29.5s\n",
      "[CV] kernel=sigmoid, C=1, gamma=0.001, class_weight=balanced .........\n",
      "[CV]  kernel=sigmoid, C=1, gamma=0.001, class_weight=balanced, score=0.337662 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 294 tasks       | elapsed:   29.5s\n",
      "[CV] kernel=sigmoid, C=1, gamma=0.0001, class_weight=balanced ........\n",
      "[CV]  kernel=sigmoid, C=1, gamma=0.0001, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 295 tasks       | elapsed:   29.5s\n",
      "[CV] kernel=sigmoid, C=1, gamma=0.0001, class_weight=balanced ........\n",
      "[CV]  kernel=sigmoid, C=1, gamma=0.0001, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 296 tasks       | elapsed:   29.6s\n",
      "[CV] kernel=sigmoid, C=1, gamma=0.0001, class_weight=balanced ........\n",
      "[CV]  kernel=sigmoid, C=1, gamma=0.0001, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 297 tasks       | elapsed:   29.6s\n",
      "[CV] kernel=sigmoid, C=1, gamma=auto, class_weight=None ..............\n",
      "[CV]  kernel=sigmoid, C=1, gamma=auto, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 298 tasks       | elapsed:   29.6s\n",
      "[CV] kernel=sigmoid, C=1, gamma=auto, class_weight=None ..............\n",
      "[CV]  kernel=sigmoid, C=1, gamma=auto, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 299 tasks       | elapsed:   29.6s\n",
      "[CV] kernel=sigmoid, C=1, gamma=auto, class_weight=None ..............\n",
      "[CV]  kernel=sigmoid, C=1, gamma=auto, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 300 tasks       | elapsed:   29.6s\n",
      "[CV] kernel=sigmoid, C=1, gamma=0.001, class_weight=None .............\n",
      "[CV]  kernel=sigmoid, C=1, gamma=0.001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 301 tasks       | elapsed:   29.6s\n",
      "[CV] kernel=sigmoid, C=1, gamma=0.001, class_weight=None .............\n",
      "[CV]  kernel=sigmoid, C=1, gamma=0.001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 302 tasks       | elapsed:   29.6s\n",
      "[CV] kernel=sigmoid, C=1, gamma=0.001, class_weight=None .............\n",
      "[CV]  kernel=sigmoid, C=1, gamma=0.001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 303 tasks       | elapsed:   29.6s\n",
      "[CV] kernel=sigmoid, C=1, gamma=0.0001, class_weight=None ............\n",
      "[CV]  kernel=sigmoid, C=1, gamma=0.0001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 304 tasks       | elapsed:   29.6s\n",
      "[CV] kernel=sigmoid, C=1, gamma=0.0001, class_weight=None ............\n",
      "[CV]  kernel=sigmoid, C=1, gamma=0.0001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 305 tasks       | elapsed:   29.6s\n",
      "[CV] kernel=sigmoid, C=1, gamma=0.0001, class_weight=None ............\n",
      "[CV]  kernel=sigmoid, C=1, gamma=0.0001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 306 tasks       | elapsed:   29.7s\n",
      "[CV] kernel=sigmoid, C=10, gamma=auto, class_weight=balanced .........\n",
      "[CV]  kernel=sigmoid, C=10, gamma=auto, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 307 tasks       | elapsed:   29.7s\n",
      "[CV] kernel=sigmoid, C=10, gamma=auto, class_weight=balanced .........\n",
      "[CV]  kernel=sigmoid, C=10, gamma=auto, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 308 tasks       | elapsed:   29.7s\n",
      "[CV] kernel=sigmoid, C=10, gamma=auto, class_weight=balanced .........\n",
      "[CV]  kernel=sigmoid, C=10, gamma=auto, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 309 tasks       | elapsed:   29.7s\n",
      "[CV] kernel=sigmoid, C=10, gamma=0.001, class_weight=balanced ........\n",
      "[CV]  kernel=sigmoid, C=10, gamma=0.001, class_weight=balanced, score=0.543689 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 310 tasks       | elapsed:   29.7s\n",
      "[CV] kernel=sigmoid, C=10, gamma=0.001, class_weight=balanced ........\n",
      "[CV]  kernel=sigmoid, C=10, gamma=0.001, class_weight=balanced, score=0.514851 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 311 tasks       | elapsed:   29.7s\n",
      "[CV] kernel=sigmoid, C=10, gamma=0.001, class_weight=balanced ........\n",
      "[CV]  kernel=sigmoid, C=10, gamma=0.001, class_weight=balanced, score=0.534653 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 312 tasks       | elapsed:   29.7s\n",
      "[CV] kernel=sigmoid, C=10, gamma=0.0001, class_weight=balanced .......\n",
      "[CV]  kernel=sigmoid, C=10, gamma=0.0001, class_weight=balanced, score=0.776978 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 313 tasks       | elapsed:   29.7s\n",
      "[CV] kernel=sigmoid, C=10, gamma=0.0001, class_weight=balanced .......\n",
      "[CV]  kernel=sigmoid, C=10, gamma=0.0001, class_weight=balanced, score=0.813793 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 314 tasks       | elapsed:   29.7s\n",
      "[CV] kernel=sigmoid, C=10, gamma=0.0001, class_weight=balanced .......\n",
      "[CV]  kernel=sigmoid, C=10, gamma=0.0001, class_weight=balanced, score=0.802721 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 315 tasks       | elapsed:   29.8s\n",
      "[CV] kernel=sigmoid, C=10, gamma=auto, class_weight=None .............\n",
      "[CV]  kernel=sigmoid, C=10, gamma=auto, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 316 tasks       | elapsed:   29.8s\n",
      "[CV] kernel=sigmoid, C=10, gamma=auto, class_weight=None .............\n",
      "[CV]  kernel=sigmoid, C=10, gamma=auto, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 317 tasks       | elapsed:   29.8s\n",
      "[CV] kernel=sigmoid, C=10, gamma=auto, class_weight=None .............\n",
      "[CV]  kernel=sigmoid, C=10, gamma=auto, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 318 tasks       | elapsed:   29.8s\n",
      "[CV] kernel=sigmoid, C=10, gamma=0.001, class_weight=None ............\n",
      "[CV]  kernel=sigmoid, C=10, gamma=0.001, class_weight=None, score=0.794521 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 319 tasks       | elapsed:   29.8s\n",
      "[CV] kernel=sigmoid, C=10, gamma=0.001, class_weight=None ............\n",
      "[CV]  kernel=sigmoid, C=10, gamma=0.001, class_weight=None, score=0.826087 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 320 tasks       | elapsed:   29.8s\n",
      "[CV] kernel=sigmoid, C=10, gamma=0.001, class_weight=None ............\n",
      "[CV]  kernel=sigmoid, C=10, gamma=0.001, class_weight=None, score=0.805556 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 321 tasks       | elapsed:   29.8s\n",
      "[CV] kernel=sigmoid, C=10, gamma=0.0001, class_weight=None ...........\n",
      "[CV]  kernel=sigmoid, C=10, gamma=0.0001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 322 tasks       | elapsed:   29.8s\n",
      "[CV] kernel=sigmoid, C=10, gamma=0.0001, class_weight=None ...........\n",
      "[CV]  kernel=sigmoid, C=10, gamma=0.0001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 323 tasks       | elapsed:   29.8s\n",
      "[CV] kernel=sigmoid, C=10, gamma=0.0001, class_weight=None ...........\n",
      "[CV]  kernel=sigmoid, C=10, gamma=0.0001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 324 tasks       | elapsed:   29.9s\n",
      "[CV] kernel=sigmoid, C=100, gamma=auto, class_weight=balanced ........\n",
      "[CV]  kernel=sigmoid, C=100, gamma=auto, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 325 tasks       | elapsed:   29.9s\n",
      "[CV] kernel=sigmoid, C=100, gamma=auto, class_weight=balanced ........\n",
      "[CV]  kernel=sigmoid, C=100, gamma=auto, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 326 tasks       | elapsed:   29.9s\n",
      "[CV] kernel=sigmoid, C=100, gamma=auto, class_weight=balanced ........\n",
      "[CV]  kernel=sigmoid, C=100, gamma=auto, class_weight=balanced, score=0.000000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 327 tasks       | elapsed:   29.9s\n",
      "[CV] kernel=sigmoid, C=100, gamma=0.001, class_weight=balanced .......\n",
      "[CV]  kernel=sigmoid, C=100, gamma=0.001, class_weight=balanced, score=0.607143 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 328 tasks       | elapsed:   29.9s\n",
      "[CV] kernel=sigmoid, C=100, gamma=0.001, class_weight=balanced .......\n",
      "[CV]  kernel=sigmoid, C=100, gamma=0.001, class_weight=balanced, score=0.724138 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 329 tasks       | elapsed:   29.9s\n",
      "[CV] kernel=sigmoid, C=100, gamma=0.001, class_weight=balanced .......\n",
      "[CV]  kernel=sigmoid, C=100, gamma=0.001, class_weight=balanced, score=0.533333 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 330 tasks       | elapsed:   29.9s\n",
      "[CV] kernel=sigmoid, C=100, gamma=0.0001, class_weight=balanced ......\n",
      "[CV]  kernel=sigmoid, C=100, gamma=0.0001, class_weight=balanced, score=0.707965 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 331 tasks       | elapsed:   29.9s\n",
      "[CV] kernel=sigmoid, C=100, gamma=0.0001, class_weight=balanced ......\n",
      "[CV]  kernel=sigmoid, C=100, gamma=0.0001, class_weight=balanced, score=0.700855 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 332 tasks       | elapsed:   29.9s\n",
      "[CV] kernel=sigmoid, C=100, gamma=0.0001, class_weight=balanced ......\n",
      "[CV]  kernel=sigmoid, C=100, gamma=0.0001, class_weight=balanced, score=0.793651 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 333 tasks       | elapsed:   30.0s\n",
      "[CV] kernel=sigmoid, C=100, gamma=auto, class_weight=None ............\n",
      "[CV]  kernel=sigmoid, C=100, gamma=auto, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 334 tasks       | elapsed:   30.0s\n",
      "[CV] kernel=sigmoid, C=100, gamma=auto, class_weight=None ............\n",
      "[CV]  kernel=sigmoid, C=100, gamma=auto, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 335 tasks       | elapsed:   30.0s\n",
      "[CV] kernel=sigmoid, C=100, gamma=auto, class_weight=None ............\n",
      "[CV]  kernel=sigmoid, C=100, gamma=auto, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 336 tasks       | elapsed:   30.0s\n",
      "[CV] kernel=sigmoid, C=100, gamma=0.001, class_weight=None ...........\n",
      "[CV]  kernel=sigmoid, C=100, gamma=0.001, class_weight=None, score=0.666667 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 337 tasks       | elapsed:   30.0s\n",
      "[CV] kernel=sigmoid, C=100, gamma=0.001, class_weight=None ...........\n",
      "[CV]  kernel=sigmoid, C=100, gamma=0.001, class_weight=None, score=0.784000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 338 tasks       | elapsed:   30.0s\n",
      "[CV] kernel=sigmoid, C=100, gamma=0.001, class_weight=None ...........\n",
      "[CV]  kernel=sigmoid, C=100, gamma=0.001, class_weight=None, score=0.633333 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 339 tasks       | elapsed:   30.0s\n",
      "[CV] kernel=sigmoid, C=100, gamma=0.0001, class_weight=None ..........\n",
      "[CV]  kernel=sigmoid, C=100, gamma=0.0001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 340 tasks       | elapsed:   30.0s\n",
      "[CV] kernel=sigmoid, C=100, gamma=0.0001, class_weight=None ..........\n",
      "[CV]  kernel=sigmoid, C=100, gamma=0.0001, class_weight=None, score=0.805369 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 341 tasks       | elapsed:   30.0s\n",
      "[CV] kernel=sigmoid, C=100, gamma=0.0001, class_weight=None ..........\n",
      "[CV]  kernel=sigmoid, C=100, gamma=0.0001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 342 tasks       | elapsed:   30.1s\n",
      "[CV] kernel=rbf, C=1, gamma=auto, class_weight=balanced ..............\n",
      "[CV]  kernel=rbf, C=1, gamma=auto, class_weight=balanced, score=0.736842 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 343 tasks       | elapsed:   30.1s\n",
      "[CV] kernel=rbf, C=1, gamma=auto, class_weight=balanced ..............\n",
      "[CV]  kernel=rbf, C=1, gamma=auto, class_weight=balanced, score=0.739496 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 344 tasks       | elapsed:   30.1s\n",
      "[CV] kernel=rbf, C=1, gamma=auto, class_weight=balanced ..............\n",
      "[CV]  kernel=rbf, C=1, gamma=auto, class_weight=balanced, score=0.741379 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 345 tasks       | elapsed:   30.1s\n",
      "[CV] kernel=rbf, C=1, gamma=0.001, class_weight=balanced .............\n",
      "[CV]  kernel=rbf, C=1, gamma=0.001, class_weight=balanced, score=0.791367 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 346 tasks       | elapsed:   30.1s\n",
      "[CV] kernel=rbf, C=1, gamma=0.001, class_weight=balanced .............\n",
      "[CV]  kernel=rbf, C=1, gamma=0.001, class_weight=balanced, score=0.822695 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 347 tasks       | elapsed:   30.1s\n",
      "[CV] kernel=rbf, C=1, gamma=0.001, class_weight=balanced .............\n",
      "[CV]  kernel=rbf, C=1, gamma=0.001, class_weight=balanced, score=0.805556 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 348 tasks       | elapsed:   30.1s\n",
      "[CV] kernel=rbf, C=1, gamma=0.0001, class_weight=balanced ............\n",
      "[CV]  kernel=rbf, C=1, gamma=0.0001, class_weight=balanced, score=0.524272 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 349 tasks       | elapsed:   30.1s\n",
      "[CV] kernel=rbf, C=1, gamma=0.0001, class_weight=balanced ............\n",
      "[CV]  kernel=rbf, C=1, gamma=0.0001, class_weight=balanced, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 350 tasks       | elapsed:   30.1s\n",
      "[CV] kernel=rbf, C=1, gamma=0.0001, class_weight=balanced ............\n",
      "[CV]  kernel=rbf, C=1, gamma=0.0001, class_weight=balanced, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 351 tasks       | elapsed:   30.1s\n",
      "[CV] kernel=rbf, C=1, gamma=auto, class_weight=None ..................\n",
      "[CV]  kernel=rbf, C=1, gamma=auto, class_weight=None, score=0.826087 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 352 tasks       | elapsed:   30.1s\n",
      "[CV] kernel=rbf, C=1, gamma=auto, class_weight=None ..................\n",
      "[CV]  kernel=rbf, C=1, gamma=auto, class_weight=None, score=0.794326 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 353 tasks       | elapsed:   30.2s\n",
      "[CV] kernel=rbf, C=1, gamma=auto, class_weight=None ..................\n",
      "[CV]  kernel=rbf, C=1, gamma=auto, class_weight=None, score=0.805556 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 354 tasks       | elapsed:   30.2s\n",
      "[CV] kernel=rbf, C=1, gamma=0.001, class_weight=None .................\n",
      "[CV]  kernel=rbf, C=1, gamma=0.001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 355 tasks       | elapsed:   30.2s\n",
      "[CV] kernel=rbf, C=1, gamma=0.001, class_weight=None .................\n",
      "[CV]  kernel=rbf, C=1, gamma=0.001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 356 tasks       | elapsed:   30.2s\n",
      "[CV] kernel=rbf, C=1, gamma=0.001, class_weight=None .................\n",
      "[CV]  kernel=rbf, C=1, gamma=0.001, class_weight=None, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 357 tasks       | elapsed:   30.2s\n",
      "[CV] kernel=rbf, C=1, gamma=0.0001, class_weight=None ................\n",
      "[CV]  kernel=rbf, C=1, gamma=0.0001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 358 tasks       | elapsed:   30.2s\n",
      "[CV] kernel=rbf, C=1, gamma=0.0001, class_weight=None ................\n",
      "[CV]  kernel=rbf, C=1, gamma=0.0001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 359 tasks       | elapsed:   30.2s\n",
      "[CV] kernel=rbf, C=1, gamma=0.0001, class_weight=None ................\n",
      "[CV]  kernel=rbf, C=1, gamma=0.0001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 360 tasks       | elapsed:   30.2s\n",
      "[CV] kernel=rbf, C=10, gamma=auto, class_weight=balanced .............\n",
      "[CV]  kernel=rbf, C=10, gamma=auto, class_weight=balanced, score=0.710744 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 361 tasks       | elapsed:   30.2s\n",
      "[CV] kernel=rbf, C=10, gamma=auto, class_weight=balanced .............\n",
      "[CV]  kernel=rbf, C=10, gamma=auto, class_weight=balanced, score=0.744186 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 362 tasks       | elapsed:   30.2s\n",
      "[CV] kernel=rbf, C=10, gamma=auto, class_weight=balanced .............\n",
      "[CV]  kernel=rbf, C=10, gamma=auto, class_weight=balanced, score=0.694215 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 363 tasks       | elapsed:   30.2s\n",
      "[CV] kernel=rbf, C=10, gamma=0.001, class_weight=balanced ............\n",
      "[CV]  kernel=rbf, C=10, gamma=0.001, class_weight=balanced, score=0.741379 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 364 tasks       | elapsed:   30.3s\n",
      "[CV] kernel=rbf, C=10, gamma=0.001, class_weight=balanced ............\n",
      "[CV]  kernel=rbf, C=10, gamma=0.001, class_weight=balanced, score=0.733333 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 365 tasks       | elapsed:   30.3s\n",
      "[CV] kernel=rbf, C=10, gamma=0.001, class_weight=balanced ............\n",
      "[CV]  kernel=rbf, C=10, gamma=0.001, class_weight=balanced, score=0.780488 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 366 tasks       | elapsed:   30.3s\n",
      "[CV] kernel=rbf, C=10, gamma=0.0001, class_weight=balanced ...........\n",
      "[CV]  kernel=rbf, C=10, gamma=0.0001, class_weight=balanced, score=0.773723 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 367 tasks       | elapsed:   30.3s\n",
      "[CV] kernel=rbf, C=10, gamma=0.0001, class_weight=balanced ...........\n",
      "[CV]  kernel=rbf, C=10, gamma=0.0001, class_weight=balanced, score=0.808511 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 368 tasks       | elapsed:   30.3s\n",
      "[CV] kernel=rbf, C=10, gamma=0.0001, class_weight=balanced ...........\n",
      "[CV]  kernel=rbf, C=10, gamma=0.0001, class_weight=balanced, score=0.816901 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 369 tasks       | elapsed:   30.3s\n",
      "[CV] kernel=rbf, C=10, gamma=auto, class_weight=None .................\n",
      "[CV]  kernel=rbf, C=10, gamma=auto, class_weight=None, score=0.741935 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 370 tasks       | elapsed:   30.3s\n",
      "[CV] kernel=rbf, C=10, gamma=auto, class_weight=None .................\n",
      "[CV]  kernel=rbf, C=10, gamma=auto, class_weight=None, score=0.748092 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 371 tasks       | elapsed:   30.3s\n",
      "[CV] kernel=rbf, C=10, gamma=auto, class_weight=None .................\n",
      "[CV]  kernel=rbf, C=10, gamma=auto, class_weight=None, score=0.720000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 372 tasks       | elapsed:   30.3s\n",
      "[CV] kernel=rbf, C=10, gamma=0.001, class_weight=None ................\n",
      "[CV]  kernel=rbf, C=10, gamma=0.001, class_weight=None, score=0.819444 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 373 tasks       | elapsed:   30.3s\n",
      "[CV] kernel=rbf, C=10, gamma=0.001, class_weight=None ................\n",
      "[CV]  kernel=rbf, C=10, gamma=0.001, class_weight=None, score=0.819444 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 374 tasks       | elapsed:   30.4s\n",
      "[CV] kernel=rbf, C=10, gamma=0.001, class_weight=None ................\n",
      "[CV]  kernel=rbf, C=10, gamma=0.001, class_weight=None, score=0.811189 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 375 tasks       | elapsed:   30.4s\n",
      "[CV] kernel=rbf, C=10, gamma=0.0001, class_weight=None ...............\n",
      "[CV]  kernel=rbf, C=10, gamma=0.0001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 376 tasks       | elapsed:   30.4s\n",
      "[CV] kernel=rbf, C=10, gamma=0.0001, class_weight=None ...............\n",
      "[CV]  kernel=rbf, C=10, gamma=0.0001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 377 tasks       | elapsed:   30.4s\n",
      "[CV] kernel=rbf, C=10, gamma=0.0001, class_weight=None ...............\n",
      "[CV]  kernel=rbf, C=10, gamma=0.0001, class_weight=None, score=0.797297 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 378 tasks       | elapsed:   30.4s\n",
      "[CV] kernel=rbf, C=100, gamma=auto, class_weight=balanced ............\n",
      "[CV]  kernel=rbf, C=100, gamma=auto, class_weight=balanced, score=0.731707 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 379 tasks       | elapsed:   30.4s\n",
      "[CV] kernel=rbf, C=100, gamma=auto, class_weight=balanced ............\n",
      "[CV]  kernel=rbf, C=100, gamma=auto, class_weight=balanced, score=0.750000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 380 tasks       | elapsed:   30.4s\n",
      "[CV] kernel=rbf, C=100, gamma=auto, class_weight=balanced ............\n",
      "[CV]  kernel=rbf, C=100, gamma=auto, class_weight=balanced, score=0.715447 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 381 tasks       | elapsed:   30.4s\n",
      "[CV] kernel=rbf, C=100, gamma=0.001, class_weight=balanced ...........\n",
      "[CV]  kernel=rbf, C=100, gamma=0.001, class_weight=balanced, score=0.666667 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 382 tasks       | elapsed:   30.4s\n",
      "[CV] kernel=rbf, C=100, gamma=0.001, class_weight=balanced ...........\n",
      "[CV]  kernel=rbf, C=100, gamma=0.001, class_weight=balanced, score=0.714286 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 383 tasks       | elapsed:   30.4s\n",
      "[CV] kernel=rbf, C=100, gamma=0.001, class_weight=balanced ...........\n",
      "[CV]  kernel=rbf, C=100, gamma=0.001, class_weight=balanced, score=0.783333 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 384 tasks       | elapsed:   30.5s\n",
      "[CV] kernel=rbf, C=100, gamma=0.0001, class_weight=balanced ..........\n",
      "[CV]  kernel=rbf, C=100, gamma=0.0001, class_weight=balanced, score=0.696429 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 385 tasks       | elapsed:   30.5s\n",
      "[CV] kernel=rbf, C=100, gamma=0.0001, class_weight=balanced ..........\n",
      "[CV]  kernel=rbf, C=100, gamma=0.0001, class_weight=balanced, score=0.774194 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 386 tasks       | elapsed:   30.5s\n",
      "[CV] kernel=rbf, C=100, gamma=0.0001, class_weight=balanced ..........\n",
      "[CV]  kernel=rbf, C=100, gamma=0.0001, class_weight=balanced, score=0.777778 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 387 tasks       | elapsed:   30.5s\n",
      "[CV] kernel=rbf, C=100, gamma=auto, class_weight=None ................\n",
      "[CV]  kernel=rbf, C=100, gamma=auto, class_weight=None, score=0.721311 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 388 tasks       | elapsed:   30.5s\n",
      "[CV] kernel=rbf, C=100, gamma=auto, class_weight=None ................\n",
      "[CV]  kernel=rbf, C=100, gamma=auto, class_weight=None, score=0.750000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 389 tasks       | elapsed:   30.5s\n",
      "[CV] kernel=rbf, C=100, gamma=auto, class_weight=None ................\n",
      "[CV]  kernel=rbf, C=100, gamma=auto, class_weight=None, score=0.725806 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 390 tasks       | elapsed:   30.5s\n",
      "[CV] kernel=rbf, C=100, gamma=0.001, class_weight=None ...............\n",
      "[CV]  kernel=rbf, C=100, gamma=0.001, class_weight=None, score=0.800000 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 391 tasks       | elapsed:   30.5s\n",
      "[CV] kernel=rbf, C=100, gamma=0.001, class_weight=None ...............\n",
      "[CV]  kernel=rbf, C=100, gamma=0.001, class_weight=None, score=0.820144 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 392 tasks       | elapsed:   30.5s\n",
      "[CV] kernel=rbf, C=100, gamma=0.001, class_weight=None ...............\n",
      "[CV]  kernel=rbf, C=100, gamma=0.001, class_weight=None, score=0.781955 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 393 tasks       | elapsed:   30.5s\n",
      "[CV] kernel=rbf, C=100, gamma=0.0001, class_weight=None ..............\n",
      "[CV]  kernel=rbf, C=100, gamma=0.0001, class_weight=None, score=0.830986 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 394 tasks       | elapsed:   30.6s\n",
      "[CV] kernel=rbf, C=100, gamma=0.0001, class_weight=None ..............\n",
      "[CV]  kernel=rbf, C=100, gamma=0.0001, class_weight=None, score=0.802817 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 395 tasks       | elapsed:   30.6s\n",
      "[CV] kernel=rbf, C=100, gamma=0.0001, class_weight=None ..............\n",
      "[CV]  kernel=rbf, C=100, gamma=0.0001, class_weight=None, score=0.808219 -   0.0s\n",
      "[Parallel(n_jobs=1)]: Done 396 tasks       | elapsed:   30.6s\n",
      "[Parallel(n_jobs=1)]: Done 396 out of 396 | elapsed:   30.6s finished\n",
      "best model is SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=2, gamma=0.001, kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Training SVC...\n",
      "Done!\n",
      "Training time (secs): 0.007\n",
      "SVC(C=100, cache_size=200, class_weight=None, coef0=0.0,\n",
      "  decision_function_shape=None, degree=2, gamma=0.001, kernel='poly',\n",
      "  max_iter=-1, probability=False, random_state=None, shrinking=True,\n",
      "  tol=0.001, verbose=False)\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.00300002098083\n",
      "F1 score for  entire training set and not the Entire Data Set(excluding test set): (0.84210526315789469, '0.003')\n",
      "Predicting labels using SVC...\n",
      "Done!\n",
      "Prediction time (secs): 0.000999927520752\n",
      "F1 score for test set: (0.83999999999999997, '0.001')\n"
     ]
    }
   ],
   "source": [
    "# TODO: Fine-tune your model and report the best F1 score\n",
    "def performance_metric(y_true, y_predicted):\n",
    "    return f1_score(y_true, y_predicted, pos_label='yes')   \n",
    "\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.cross_validation import StratifiedShuffleSplit\n",
    "from sklearn import svm\n",
    "svm_clf = svm.SVC()\n",
    "param_grid = [{'C':[1, 10, 100], 'kernel':['linear'],  'class_weight':['balanced',None]  },\n",
    "              {'C':[1, 10, 100], 'kernel':['poly'],    'class_weight':['balanced',None], 'gamma':['auto',0.001,0.0001], \n",
    "               'degree':[2,3,4,5,6]  },\n",
    "              {'C':[1, 10, 100], 'kernel':['sigmoid'], 'class_weight':['balanced',None],'gamma':['auto',0.001,0.0001] },\n",
    "              {'C':[1, 10, 100], 'kernel':['rbf'],     'class_weight':['balanced',None],'gamma':['auto',0.001,0.0001] }\n",
    "             ]\n",
    "cv = StratifiedShuffleSplit(y_train, n_iter=3, test_size=0.3, random_state=40)\n",
    "gs_clf = GridSearchCV(svm_clf, param_grid = param_grid, scoring= make_scorer(performance_metric, greater_is_better=True), \n",
    "                      verbose = 100, cv = cv, refit = True)\n",
    "gs_clf.fit(X_train, y_train)\n",
    "print 'best model is',gs_clf.best_estimator_\n",
    "gs_clf = gs_clf.best_estimator_\n",
    "\n",
    "train_classifier(gs_clf , X_train, y_train)  # note: using entire training set here\n",
    "print gs_clf  # you can inspect the learned model by printing it\n",
    "print \"F1 score for  entire training set and not the Entire Data Set(excluding test set): {}\"\\\n",
    "         .format(predict_labels(gs_clf, X_train, y_train))\n",
    "print \"F1 score for test set: {}\".format(predict_labels(gs_clf, X_test, y_test))\n",
    "\n",
    "#####\n",
    "#print('################################  Original untweaked model of the SVM')\n",
    "####\n",
    "# from sklearn import svm\n",
    "# clf = svm.SVC()\n",
    "# train_classifier(clf, X_train, y_train)  # note: using entire training set here\n",
    "# print clf  # you can inspect the learned model by printing it\n",
    "# print \"F1 score for training set: {}\".format(predict_labels(clf, X_train, y_train))\n",
    "# print \"F1 score for test set: {}\".format(predict_labels(clf, X_test, y_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "** What is the model's final F<sub>1</sub> score?**   \n",
    "**Answer :** 0.84"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
